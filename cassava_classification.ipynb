{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassava classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edyDFX_Ih5-j"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "cudnn.benchmark = True\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from utils import Mixup, RandAugment\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the root directory dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waXTuqeVh5-q"
   },
   "outputs": [],
   "source": [
    "root = os.path.join(os.environ[\"HOME\"], \"Workspace/datasets/taiyoyuden/cassava\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split files from the dataset into the train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files in the dataset are broken, so we will use only those image files that OpenCV could load correctly. We will use 20000 images for training, 4936 images for validation, and 10 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgLoujrNHY5Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_images',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'external',\n",
       " 'sample_submission.csv',\n",
       " 'train_images',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to visualize images and their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will take a list of images' file paths and their labels and visualize them in a grid. Correct labels are colored green, and incorrectly predicted labels are colored red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "train_external = pd.read_csv(f'{root}/external/train_external.csv')\n",
    "test_external = pd.read_csv(f'{root}/external/test_external.csv')\n",
    "test_external_pseudo = pd.read_csv(f'{root}/external/test_external_pseudo.csv')\n",
    "test = pd.read_csv(f'{root}/sample_submission.csv')\n",
    "label_map = pd.read_json(f'{root}/label_num_to_disease_map.json', \n",
    "                         orient='index')\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7320,  910, 5440, 5241, 5784, 6315,  516, 4476, 5628, 8372, 1735,\n",
       "        819, 6999, 2483, 5361, 5101, 6470, 1234, 4605, 3435, 6446, 8716,\n",
       "       9324, 2608, 7899, 2097, 2797, 9217,  239, 2784, 3055, 4708, 1949,\n",
       "       7784, 1317, 1578, 3606, 3940, 8888, 5443, 8842, 8483, 7563, 2662,\n",
       "       7091, 9605, 6285, 5536, 7149, 9720])"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map.iloc[1].values\n",
    "np.random.randint(50, 10000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ho-BaziAHY5q"
   },
   "outputs": [],
   "source": [
    "def visualize_input_image_grid(filepaths, image_name, labels, cols=4):\n",
    "    rows = 5\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(25, 15))\n",
    "    for i, index in enumerate(np.random.randint(0, len(image_name), 20)):\n",
    "        name = image_name.iloc[index]['image_id']\n",
    "        label =  image_name.iloc[index]['label']\n",
    "        image = cv2.imread(f'{filepaths}/train_images/{name}')\n",
    "        if (i == 0): \n",
    "            print(image.shape)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_title(label, color='GREEN')\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters of the whole process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = [\"resnest26d\",\"efficientnet_b2_ns\", \"skresnet34d\" ,\"cspresnet50\", \"vit_base_patch16_384\"]\n",
    "weights = [\n",
    "    \"weights/resnest26d_fold0_best_epoch_28_final_1st.pth\",\n",
    "    \"weights/resnest26d_fold0_best_epoch_13_final_mixup.pth\",\n",
    "        \n",
    "]\n",
    "model_index = 0\n",
    "ckpt_index = 1\n",
    "\n",
    "params = {\n",
    "    \"visualize\": False,\n",
    "    \"fold\": 4,\n",
    "    \"train_external\": False,\n",
    "    \"test_external\": False,\n",
    "    \"load_pretrained\": False,\n",
    "    \"resume\": False,\n",
    "    \"image_size\": 256,\n",
    "    \"num_classes\": 5,\n",
    "    \"model\": models_name[model_index],\n",
    "    \"device\": \"cuda\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\":1e-6,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 30,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"drop_block\": 0.2,\n",
    "    \"drop\": 0.2,\n",
    "    \"mix_up\": False,\n",
    "    \"cutmix\":False,\n",
    "    \"rand_aug\": False,\n",
    "    \"local_rank\":0,\n",
    "    \"distributed\": False,\n",
    "    \"hard_negative_sample\": False,\n",
    "    \"tta\": False,\n",
    "    \"train_phase\":True,\n",
    "    \"balance_data\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset with KFolds strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let visualize the dataset with the defined class, the proceed the split dataset with 5 folds\n",
    "Then, we can add the external dataset to each fold and visualize the class distribution of the dataset\n",
    "\n",
    "The class dataset is defined with transform and random augmentation.\n",
    "\n",
    "`__init__` will receive an optional `transform` argument. It is a transformation function of the Albumentations augmentation pipeline. Then in `__getitem__`, the Dataset class will use that function to augment an image and return it along with the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['visualize']:\n",
    "    visualize_input_image_grid(root, train, label_map)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  label\n",
      "0     0         218\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2631\n",
      "      4         516\n",
      "1     0         218\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2631\n",
      "      4         516\n",
      "2     0         217\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2632\n",
      "      4         515\n",
      "3     0         217\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2632\n",
      "      4         515\n",
      "4     0         217\n",
      "      1         437\n",
      "      2         478\n",
      "      3        2632\n",
      "      4         515\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['label'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold','label']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>998910982.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  fold\n",
       "0      1000015157.jpg      0     3\n",
       "1      1000201771.jpg      3     2\n",
       "2       100042118.jpg      1     2\n",
       "3      1000723321.jpg      1     1\n",
       "4      1000812911.jpg      3     2\n",
       "...               ...    ...   ...\n",
       "17113   998910982.jpg      1     1\n",
       "17114   999068805.jpg      3     1\n",
       "17115   999329392.jpg      3     0\n",
       "17116   999474432.jpg      1     1\n",
       "17117   999616605.jpg      4     2\n",
       "\n",
       "[17118 rows x 3 columns]"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = params[\"fold\"]\n",
    "train_idx = folds[folds['fold'] != fold].index\n",
    "val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "train_folds = folds.loc[train_idx].reset_index(drop=True)\n",
    "val_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-cbsd-663.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cgm-560.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cmd-1576.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-443.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-cgm-293.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>train-cmd-1383.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>train-cmd-971.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>train-cbb-402.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>train-cbsd-1029.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>train-cmd-2291.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id  label  fold\n",
       "0      train-cbsd-663.jpg      1     4\n",
       "1       train-cgm-560.jpg      2     4\n",
       "2      train-cmd-1576.jpg      3     4\n",
       "3       train-cbb-443.jpg      0     4\n",
       "4       train-cgm-293.jpg      2     4\n",
       "...                   ...    ...   ...\n",
       "5651   train-cmd-1383.jpg      3     4\n",
       "5652    train-cmd-971.jpg      3     4\n",
       "5653    train-cbb-402.jpg      0     4\n",
       "5654  train-cbsd-1029.jpg      1     4\n",
       "5655   train-cmd-2291.jpg      3     4\n",
       "\n",
       "[5656 rows x 3 columns]"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_external\n",
    "for idx,label in enumerate(train_external['label']):\n",
    "    train_external.loc[idx,'fold'] = fold\n",
    "train_external['fold'] = train_external['fold'].astype(int)\n",
    "train_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df1, df2):\n",
    "    merge_df = pd.concat([df1, df2], axis=0) #,how ='outer', on ='image_id')\n",
    "    return merge_df\n",
    "\n",
    "if params[\"train_external\"]:\n",
    "    train_folds = merge_data(train_folds, train_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>998910982.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  fold\n",
       "0      1000015157.jpg      0     3\n",
       "1      1000201771.jpg      3     2\n",
       "2       100042118.jpg      1     2\n",
       "3      1000723321.jpg      1     1\n",
       "4      1000812911.jpg      3     2\n",
       "...               ...    ...   ...\n",
       "17113   998910982.jpg      1     1\n",
       "17114   999068805.jpg      3     1\n",
       "17115   999329392.jpg      3     0\n",
       "17116   999474432.jpg      1     1\n",
       "17117   999616605.jpg      4     2\n",
       "\n",
       "[17118 rows x 3 columns]"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     1087\n",
      "1     2189\n",
      "2     2386\n",
      "3    13158\n",
      "4     2577\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAFNCAYAAACAH1JNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhkdX3v8fdHFpGADMpIYAYdVOINGtcOYsw1BpVFhCHEcImoqFxJbjRixCh4VXC57luISyRixCUCEiOoGEVBjbmA9IABAbmMCGEAYWTYURD53j/q11o03dM1011dc5r363nq6XN+Z/ueqpqnPnN+Z0lVIUmSpO54wKgLkCRJ0roxwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgpA1YkqOTfHaE2/92kv/Zhg9K8o05XPdFSZ7Zhud0P5O8Ickn5mp967DdP0lyVZLbkjxpgPl//f7OQ23bJvlukluTvH+GeZ+ZZNVapn8qydvnqK4rkjy7Da/T9yBJJXn0XNQhdY0BThqxJC9IMt5+9K9N8rUkfzjquiarqs9V1e4zzTfoj3tVPbaqvj3buqYKG1X1jqqal2A0yfuAV1bVFlV1/lyuuD/orKdDgZ8BD66qw+eorE5IsqyFvY1HXYs0Vwxw0ggleQ3wIeAdwLbAw4GPAstHWdcwLfAf0UcAF426iGk8Ari4vHu7tCAY4KQRSbIV8FbgFVX1xaq6vap+WVVfrqq/nWaZLyT5aZKbW3fYY/umPTfJxa2L7Ookr23t2yT5SpKbkqxJ8u9Jpvy3n+Q5SX7U1v9hIH3TXpLke204ST6Y5PoktyS5MMnjkhwKHAS8rh1R/HKb/4okr09yAXB7ko2nOKK0WZITW/3nJXlC37bv1VU2cZQvyW8BXwO2b9u7Lcn2k7vikuzbumxvat2Wv9s37Yokr01yQdvvE5NsNs3784Akb0xyZdv3TyfZKskDk9wGbAT8Z5Ifr8f7+6gkZyS5IcnPknwuyaI27TP0wv2X2z6+bqbvw6Ttfgo4uO9zeXar+UNJrmmvDyV54DTLP6l9JrcmORGY8v2ZZtlp92tdJfnbdpT6miQvmzRt7yTnt+/jVUmO7pv83fb3prb/T5vLuqRRMMBJo/M0ej+E/7oOy3wN2Al4GHAe8Lm+accBf1FVWwKPA85o7YcDq4DF9I7yvQG4z1GYJNsAXwTeCGwD/Bh4+jR17A48A/gdYCvgAOCGqjq21fSe1o24T98yfw7sDSyqqrunWOdy4AvAQ4B/Br6UZJNp3wmgqm4H9gKuadvboqqumbRfvwN8Hnh1ew9OoxeENu2b7QBgT2BH4PHAS6bZ5Eva64+BRwJbAB+uqjuraos2zxOq6lGTFxzg/Q3wTmB74HeBHYCj236+CPgvYJ+2j+9py6zt+/BrVfUS7v25fBP438CuwBOBJwC7tNom170p8CXgM/Q+my8Afzppnpsyfbf/tPu1LpLsCbwWeA69fZ7cnXw78GJgEb3v2f9Ksl+b9oz2d1Hb/7Pmqi5pVAxw0ug8FPjZNGFmSlX1yaq6tarupPdj84T0juQB/BLYOcmDq+rGqjqvr3074BHtCN+/T9ON9lzgoqo6uap+Sa9r96fTlPJLYEvgvwGpqkuq6toZyj+mqq6qqp9PM31F37Y/QC/c7jrDOgfxP4CvVtXpbd3vAx4E/MGk2q6pqjXAl+mFmqkcBHygqi6vqtuAI4EDM1i38Frf36pa2Wq8s6pW03sP/mhtK5zh+zCTg4C3VtX1bXtvAV40xXy7ApsAH2rfn5OBcyfVsaiqvjdNjeu8X9M4APinqvphC+5HT9rOt6vqwqq6p6ouoBfap93OHNYljYQBThqdG4BtBvzxJ8lGSd6V5MdJbgGuaJO2aX//lF5IuDLJd5I8rbW/F1gJfCPJ5UmOmGYT2wNXTYy0kHfVVDNW1RnAh4GPANcnOTbJg2fYhSnXNdX0qrqH3lHD7WdYZhDbA1dOWvdVwJK+efqD6h30jqzNuK42vDG9I5uD1DHt+5veVaInpNf9fQvwWX7z2d7HAN+HQeqZvC9Tvd/bA1dPCv1XTjHfdHWu037NUG//d+heNSR5apIzk6xOcjPwl2vbzhzWJY2EAU4anbOAO4H9ZpqxeQG9bsZn0+u2XNbaA1BV51bVcnrdaV8CTmrtt1bV4VX1SGBf4DVJnjXF+q+l143UW2mS/vHJquqYqnoKsDO9rtSJ8/amO0l+ppPn+7f9AGApMNEdegewed+8v70O672G3gn8E+ue2K+rZ1huxnXROy/tbuC6AZad6f19B719+b2qejDwQvrOkeO++7nW78MAptqXa6aY71pgSau3f95BzbRfg7rX+zdFDf8MnArsUFVbAf/Qt52pviNzVZc0EgY4aUSq6mbgzcBHkuyXZPMkmyTZK8l7plhkS3qB7wZ6YeYdExOSbJrefdq2at1ztwD3tGnPS/Lo9gN8M/CriWmTfBV4bJL921HBV3HvoPRrSX6/HfHYhN65R7/oW+d19M4PW1dP6dv2q9u+nt2m/QB4QTvqtCf37uq6DnjoWroOTwL2TvKsVu/hbd3/dz1q/DzwN0l2TLIFvc/gxAG7wWd6f7cEbgNuTrKE3wTiCZPf12m/D+uwL29Msridn/dmekehJjuLXkh9Vft+7k/vfLlBzbRfgzoJeEmSnZNsDhw1xXbWVNUvkuxCL+BOWE3v+zn5/ZuLuqSRMMBJI1RV7wdeQ+/k8dX0uoheSe8I2mSfptdtdDVwMb8JNxNeBFzRuoP+kt45TtA74fub9H6szgI+WlVnTlHLz4A/A95FLxTsBPzHNKU/GPhH4MZW0w30umqhdzHFzu3E9qn2Yzqn0Dtf7ca2L/u3MApwGLAPcFPbr1+vt6p+RC+MXN62ea9uwKq6lN7Rlb+ndx+0fehdDHDXOtQ24ZP0Tub/LvATesH1rwdZcID39y3Ak+mF7K/Su+Ch3zvpBa6b0rvCeKbvw0zeDowDFwAX0rsI4j7372vv0/70Lt5YQ+8zuldt7crO/z7Ndmbar4FU1dfonTd4Br1TAs6YNMtfAW9Nciu9MHpS37J3AP8H+I/2/u06V3VJoxJvCSRJktQtHoGTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI4Z6A7wC8k222xTy5YtG3UZkiRJM1qxYsXPqmrx5Pb7XYBbtmwZ4+Pjoy5DkiRpRkmmfHSdXaiSJEkdY4CTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSx9zvnoUqSeq+ZNQVrJ+qUVeghcIjcJIkSR1jgJMkSeoYA5wkSVLHGOAkSZI6xgAnSZLUMQY4SZKkjjHASZIkdYwBTpIkqWMMcJIkSR1jgJMkSeoYA5wkSVLHGOAkSZI6xgAnSZLUMQY4SZKkjjHASZIkdYwBTpIkqWMMcJIkSR1jgJMkSeqYoQW4JJ9Mcn2SH/a1vTfJj5JckORfkyzqm3ZkkpVJLk2yR1/7nq1tZZIj+tp3THJOaz8xyabD2hdJkqQNyTCPwH0K2HNS2+nA46rq8cD/A44ESLIzcCDw2LbMR5NslGQj4CPAXsDOwJ+3eQHeDXywqh4N3AgcMsR9kSRJ2mAMLcBV1XeBNZPavlFVd7fRs4GlbXg5cEJV3VlVPwFWAru018qquryq7gJOAJYnCbAbcHJb/nhgv2HtiyRJ0oZklOfAvQz4WhteAlzVN21Va5uu/aHATX1hcKJdkiRpwRtJgEvyv4G7gc/N0/YOTTKeZHz16tXzsUlJkqShmfcAl+QlwPOAg6qqWvPVwA59sy1tbdO13wAsSrLxpPYpVdWxVTVWVWOLFy+ek/2QJEkalXkNcEn2BF4H7FtVd/RNOhU4MMkDk+wI7AR8HzgX2KldcbopvQsdTm3B70zg+W35g4FT5ms/JEmSRmmYtxH5PHAW8Jgkq5IcAnwY2BI4PckPkvwDQFVdBJwEXAz8G/CKqvpVO8ftlcDXgUuAk9q8AK8HXpNkJb1z4o4b1r5IkiRtSPKbXsz7h7GxsRofHx91GZKkWUhGXcH6uZ/95GoOJFlRVWOT230SgyRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpY4YW4JJ8Msn1SX7Y1/aQJKcnuaz93bq1J8kxSVYmuSDJk/uWObjNf1mSg/van5LkwrbMMUkyrH2RJEnakAzzCNyngD0ntR0BfKuqdgK+1cYB9gJ2aq9DgY9BL/ABRwFPBXYBjpoIfW2el/ctN3lbkiRJC9LQAlxVfRdYM6l5OXB8Gz4e2K+v/dPVczawKMl2wB7A6VW1pqpuBE4H9mzTHlxVZ1dVAZ/uW5ckSdKCNt/nwG1bVde24Z8C27bhJcBVffOtam1ra181RbskSdKCN7KLGNqRs5qPbSU5NMl4kvHVq1fPxyYlSZKGZr4D3HWt+5P29/rWfjWwQ998S1vb2tqXTtE+pao6tqrGqmps8eLFs94JSZKkUZrvAHcqMHEl6cHAKX3tL25Xo+4K3Ny6Wr8O7J5k63bxwu7A19u0W5Ls2q4+fXHfuiRJkha0jYe14iSfB54JbJNkFb2rSd8FnJTkEOBK4IA2+2nAc4GVwB3ASwGqak2StwHntvneWlUTF0b8Fb0rXR8EfK29JEmSFrz0TkW7/xgbG6vx8fFRlyFJmoWu3vnzfvaTqzmQZEVVjU1u90kMkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOGSjAJfnDJC9tw4uT7DjcsiRJkjSdGQNckqOA1wNHtqZNgM8OsyhJkiRNb5AjcH8C7AvcDlBV1wBbDrMoSZIkTW+QAHdXVRVQAEl+a7glSZIkaW0GCXAnJfk4sCjJy4FvAv843LIkSZI0nY1nmqGq3pfkOcAtwGOAN1fV6UOvTJIkSVOaMcABtMBmaJMkSdoAzBjgktxKO/+tz83AOHB4VV0+jMIkSZI0tUGOwH0IWAX8MxDgQOBRwHnAJ4FnDqs4SZIk3dcgFzHsW1Ufr6pbq+qWqjoW2KOqTgS2HnJ9kiRJmmSQAHdHkgOSPKC9DgB+0aZN7lqVJEnSkA0S4A4CXgRcD1zXhl+Y5EHAK4dYmyRJkqYwyG1ELgf2mWby9+a2HEmSJM1kkKtQNwMOAR4LbDbRXlUvG2JdkiRJmsYgXaifAX4b2AP4DrAUuHWYRUmSJGl6gwS4R1fVm4Dbq+p4YG/gqcMtS5IkSdMZJMD9sv29KcnjgK2Ahw2vJEmSJK3NIAHu2CRbA28CTgUuBt4zm40m+ZskFyX5YZLPJ9ksyY5JzkmyMsmJSTZt8z6wja9s05f1refI1n5pkj1mU5MkSVJXzBjgquoTVXVjVX2nqh5ZVQ+rqn9Y3w0mWQK8ChirqscBG9F7usO7gQ9W1aOBG+ldOEH7e2Nr/2CbjyQ7t+UeC+wJfDTJRutblyRJUlcMchXqIuDFwLL++avqVbPc7oOS/BLYHLgW2A14QZt+PHA08DFgeRsGOBn4cJK09hOq6k7gJ0lWArsAZ82iLkmSpA3eIM9CPQ04G7gQuGe2G6yqq5O8D/gv4OfAN4AVwE1VdXebbRWwpA0vAa5qy96d5Gbgoa397L5V9y9zL0kOBQ4FePjDHz7bXZAkSRqpQQLcZlX1mrnaYDufbjmwI3AT8AV6XaBD057feizA2NiYj/+SJEmdNtB94JK8PMl2SR4y8ZrFNp8N/KSqVlfVL4EvAk8HFiWZCJRLgavb8NXADgBt+lbADf3tUywjSZK0YA0S4O4C3kvv3LIV7TU+i23+F7Brks3buWzPondl65nA89s8BwOntOFT2zht+hlVVa39wHaV6o7ATsD3Z1GXJElSJwzShXo4vZv5/mwuNlhV5yQ5GTgPuBs4n1735leBE5K8vbUd1xY5jt5RwJXAGnpXnlJVFyU5iV74uxt4RVX9ai5qlCRJ2pCldzBrLTMk3wD2q6o75qek4RobG6vx8dkcQJQkjVoy6grWzww/udJ9JFlRVWOT2wc5Anc78IMkZwJ3TjTO8jYikiRJWk+DBLgvtZckSZI2ADMGuPYAe0mSJG0gpg1wSU6qqgOSXAjcp9e+qh4/1MokSZI0pbUdgTus/X3efBQiSZKkwUwb4Krq2vb3yvkrR5IkSTMZ5Ea+kiRJ2oAY4CRJkjpm2gCX5Fvt77vnrxxJkiTNZG0XMWyX5A+AfZOcANzrvtdVdd5QK5MkSdKU1hbg3gy8CVgKfGDStAJ2G1ZRkiRJmt7arkI9GTg5yZuq6m3zWJMkSZLWYpAnMbwtyb7AM1rTt6vqK8MtS5IkSdOZ8SrUJO+kd1Pfi9vrsCTvGHZhkiRJmtogD7PfG3hiVd0DkOR44HzgDcMsTJIkSVMb9D5wi/qGtxpGIZIkSRrMIEfg3gmcn+RMercSeQZwxFCrkiRJ0rQGuYjh80m+Dfx+a3p9Vf10qFVJkiRpWoMcgZt4sP2pQ65FkiRJA/BZqJIkSR1jgJMkSeqYtQa4JBsl+dF8FSNJkqSZrTXAVdWvgEuTPHye6pEkSdIMBrmIYWvgoiTfB26faKyqfYdWlSRJkqY1SIB709CrkCRJ0sAGuQ/cd5I8Atipqr6ZZHNgo+GXJkmSpKkM8jD7lwMnAx9vTUuALw2zKEmSJE1vkNuIvAJ4OnALQFVdBjxsmEVJkiRpeoMEuDur6q6JkSQbAzW8kiRJkrQ2gwS47yR5A/CgJM8BvgB8ebhlSZIkaTqDBLgjgNXAhcBfAKcBb5zNRpMsSnJykh8luSTJ05I8JMnpSS5rf7du8ybJMUlWJrkgyZP71nNwm/+yJAfPpiZJkqSuGOQq1HuSHA+cQ6/r9NKqmm0X6t8B/1ZVz0+yKbA58AbgW1X1riRH0AuOrwf2AnZqr6cCHwOemuQhwFHAWKtrRZJTq+rGWdYmSZK0QRvkKtS9gR8DxwAfBlYm2Wt9N5hkK+AZwHEAVXVXVd0ELAeOb7MdD+zXhpcDn66es4FFSbYD9gBOr6o1LbSdDuy5vnVJkiR1xSA38n0/8MdVtRIgyaOArwJfW89t7kivS/afkjwBWAEcBmxbVde2eX4KbNuGlwBX9S2/qrVN1y5JkrSgDXIO3K0T4a25HLh1FtvcGHgy8LGqehK9x3Md0T9D66KdsytdkxyaZDzJ+OrVq+dqtZIkSSMxbYBLsn+S/YHxJKcleUm7UODLwLmz2OYqYFVVndPGT6YX6K5rXaO0v9e36VcDO/Qtv7S1Tdd+H1V1bFWNVdXY4sWLZ1G6JEnS6K3tCNw+7bUZcB3wR8Az6XV/Pmh9N1hVPwWuSvKY1vQs4GLgVGDiStKDgVPa8KnAi9vVqLsCN7eu1q8DuyfZul2xuntrkyRJWtCmPQeuql46xO3+NfC5dgXq5cBL6YXJk5IcAlwJHNDmPQ14LrASuKPNS1WtSfI2fnM08K1VtWaINUuSJG0QMtMdQZLsSC9wLaMv8FXVvkOtbEjGxsZqfHx81GVIkmYhGXUF62fWN+HS/U6SFVU1Nrl9kKtQv0Tvlh9fBu6Z68IkSZK0bgYJcL+oqmOGXokkSZIGMkiA+7skRwHfAO6caKyq84ZWlSRJkqY1SID7PeBFwG78pgu12rgkSZLm2SAB7s+AR1bVXcMuRpIkSTMb5EkMPwQWDbsQSZIkDWaQI3CLgB8lOZd7nwPXyduISJIkdd0gAe6ooVchSZKkgc0Y4KrqO/NRiCRJkgYzY4BLciu9q04BNgU2AW6vqgcPszBJkiRNbZAjcFtODCcJsBzYdZhFSZIkaXqDXIX6a9XzJWCPIdUjSZKkGQzShbp/3+gDgDHgF0OrSJIkSWs1yFWo+/QN3w1cQa8bVZIkSSMwyDlwL52PQiRJkjSYaQNckjevZbmqqrcNoR5JkiTNYG1H4G6fou23gEOAhwIGOEmSpBGYNsBV1fsnhpNsCRwGvBQ4AXj/dMtJkiRpuNZ6DlyShwCvAQ4CjgeeXFU3zkdhkiRJmtrazoF7L7A/cCzwe1V127xVJUmSpGmt7Ua+hwPbA28ErklyS3vdmuSW+SlPkiRJk63tHLh1ekqDJEmS5ochTZIkqWMMcJIkSR1jgJMkSeoYA5wkSVLHGOAkSZI6xgAnSZLUMQY4SZKkjjHASZIkdczIAlySjZKcn+QrbXzHJOckWZnkxCSbtvYHtvGVbfqyvnUc2dovTbLHaPZEkiRpfo3yCNxhwCV94+8GPlhVjwZuBA5p7YcAN7b2D7b5SLIzcCDwWGBP4KNJNpqn2iVJkkZmJAEuyVJgb+ATbTzAbsDJbZbjgf3a8PI2Tpv+rDb/cuCEqrqzqn4CrAR2mZ89kCRJGp1RHYH7EPA64J42/lDgpqq6u42vApa04SXAVQBt+s1t/l+3T7GMJEnSgjXvAS7J84Drq2rFPG7z0CTjScZXr149X5uVJEkailEcgXs6sG+SK4AT6HWd/h2wKMnGbZ6lwNVt+GpgB4A2fSvghv72KZa5l6o6tqrGqmps8eLFc7s3kiRJ82zeA1xVHVlVS6tqGb2LEM6oqoOAM4Hnt9kOBk5pw6e2cdr0M6qqWvuB7SrVHYGdgO/P025IkiSNzMYzzzJvXg+ckOTtwPnAca39OOAzSVYCa+iFPqrqoiQnARcDdwOvqKpfzX/ZkiRJ8yu9g1n3H2NjYzU+Pj7qMiRJs5CMuoL1cz/7ydUcSLKiqsYmt/skBkmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgJEmSOmbjURcgSZLuv5JRV7B+qka7fY/ASZIkdYwBTpIkqWMMcJIkSR3jOXCS7jc810bSQuEROEmSpI4xwEmSJHWMAU6SJKlj5j3AJdkhyZlJLk5yUZLDWvtDkpye5LL2d+vWniTHJFmZ5IIkT+5b18Ft/suSHDzf+6KFL+nmS5K0sI3iCNzdwOFVtTOwK/CKJDsDRwDfqqqdgG+1cYC9gJ3a61DgY9ALfMBRwFOBXYCjJkKfJEnSQjbvAa6qrq2q89rwrcAlwBJgOXB8m+14YL82vBz4dPWcDSxKsh2wB3B6Va2pqhuB04E953FXJEmSRmKk58AlWQY8CTgH2Laqrm2Tfgps24aXAFf1LbaqtU3XPtV2Dk0ynmR89erVc1a/JEnSKIwswCXZAvgX4NVVdUv/tKoqYM7ufFRVx1bVWFWNLV68eK5WK0mSNBIjCXBJNqEX3j5XVV9szde1rlHa3+tb+9XADn2LL21t07VLkiQtaKO4CjXAccAlVfWBvkmnAhNXkh4MnNLX/uJ2NequwM2tq/XrwO5Jtm4XL+ze2iRJkha0UTxK6+nAi4ALk/ygtb0BeBdwUpJDgCuBA9q004DnAiuBO4CXAlTVmiRvA85t8721qtbMzy5IkiSNTup+9pC9sbGxGh8fH3UZ6oiu3lPtfvbPemB+nguHn+XC4We5dklWVNXY5HafxCBJktQxBjhJkqSOMcBJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRJkjrGACdJktQxBjhJkqSOMcBJkiR1jAFOkiSpYzYedQELkQ/mlSRJw+QROEmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI4xwEmSJHWMAU6SJKljDHCSJEkdY4CTJEnqGAOcJElSxxjgJEmSOsYAJ0mS1DEGOEmSpI7pfIBLsmeSS5OsTHLEqOuRJEkatk4HuCQbAR8B9gJ2Bv48yc6jrUqSJGm4Oh3ggF2AlVV1eVXdBZwALB9xTZIkSUPV9QC3BLiqb3xVa5MkSVqwNh51AfMhyaHAoW30tiSXjrKeWdoG+NkwVpwMY61aCz/LhcXPc+Hws1w4FsJn+YipGrse4K4GdugbX9ra7qWqjgWOna+ihinJeFWNjboOzZ6f5cLi57lw+FkuHAv5s+x6F+q5wE5JdkyyKXAgcOqIa5IkSRqqTh+Bq6q7k7wS+DqwEfDJqrpoxGVJkiQNVacDHEBVnQacNuo65tGC6AoW4Ge50Ph5Lhx+lgvHgv0sU1WjrkGSJEnroOvnwEmSJN3vGOA6xMeGLQxJPpnk+iQ/HHUtmp0kOyQ5M8nFSS5Kctioa9L6S7JZku8n+c/2eb5l1DVpdpJslOT8JF8ZdS1zzQDXET42bEH5FLDnqIvQnLgbOLyqdgZ2BV7hv8tOuxPYraqeADwR2DPJriOuSbNzGHDJqIsYBgNcd/jYsAWiqr4LrBl1HZq9qrq2qs5rw7fS+6HwaTAdVT23tdFN2ssTxTsqyVJgb+ATo65lGAxw3eFjw6QNWJJlwJOAc0ZbiWajdbn9ALgeOL2q/Dy760PA64B7Rl3IMBjgJGmWkmwB/Avw6qq6ZdT1aP1V1a+q6on0nuyzS5LHjbomrbskzwOur6oVo65lWAxw3THQY8Mkza8km9ALb5+rqi+Ouh7Njaq6CTgTz1ftqqcD+ya5gt4pR7sl+exoS5pbBrju8LFh0gYmSYDjgEuq6gOjrkezk2RxkkVt+EHAc4AfjbYqrY+qOrKqllbVMnq/l2dU1QtHXNacMsB1RFXdDUw8NuwS4CQfG9ZNST4PnAU8JsmqJIeMuiatt6cDL6L3v/sftNdzR12U1tt2wJlJLqD3n5ReZccAAAGfSURBVObTq2rB3X5CC4NPYpAkSeoYj8BJkiR1jAFOkiSpYwxwkiRJHWOAkyRJ6hgDnCRJUscY4CRpkiS3zTzXr+c9Oslrh7V+SZqKAU6SJKljDHCSNIAk+yQ5J8n5Sb6ZZNu+yU9IclaSy5K8vG+Zv01ybpILkrxlBGVLWqAMcJI0mO8Bu1bVk+g9W/F1fdMeD+wGPA14c5Ltk+wO7ATsAjwReEqSZ8xzzZIWqI1HXYAkdcRS4MQk2wGbAj/pm3ZKVf0c+HmSM+mFtj8EdgfOb/NsQS/QfXf+Spa0UBngJGkwfw98oKpOTfJM4Oi+aZOfSVhAgHdW1cfnpzxJ9yd2oUrSYLYCrm7DB0+atjzJZkkeCjyT3oPQvw68LMkWAEmWJHnYfBUraWHzCJwk3dfmSVb1jX+A3hG3LyS5ETgD2LFv+gXAmcA2wNuq6hrgmiS/C5yVBOA24IXA9cMvX9JCl6rJR/4lSZK0IbMLVZIkqWMMcJIkSR1jgJMkSeoYA5wkSVLHGOAkSZI6xgAnSZLUMQY4SZKkjjHASZIkdcz/B8DlklDCxCjNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     466\n",
      "1    1443\n",
      "2     773\n",
      "3    2658\n",
      "4     316\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0      870\n",
      "1     1752\n",
      "2     1908\n",
      "3    10526\n",
      "4     2062\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_class_dis(df, fold, color='maroon'):\n",
    "    x = df.groupby('label').count()\n",
    "    print(x['image_id'])\n",
    "    y = [0,1,2,3,4]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.bar(y, x['image_id'].values, color =color, width = 0.4)\n",
    "    plt.xlabel(\"Label\") \n",
    "    plt.ylabel(\"Number of image\") \n",
    "    plt.title(f\"Class distribution of data fold: {fold}\") \n",
    "\n",
    "    # plt.xticks(x['image_id'])\n",
    "    plt.show()\n",
    "visualize_class_dis(train, 'all data', color='blue')\n",
    "visualize_class_dis(train_external, 'external data', color='purple')\n",
    "visualize_class_dis(train_folds, params['fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"test_external\"]:\n",
    "    train_folds = merge_data(train_folds, test_external_pseudo)\n",
    "    visualize_class_dis(train_folds, f'fold {fold} add extra pseudo test external data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(df, mode=\"undersampling\"):\n",
    "    class_0 = df[df.label==0]\n",
    "    class_1 = df[df.label==1]\n",
    "    class_2 = df[df.label==2]\n",
    "    class_3 = df[df.label==3]\n",
    "    class_4 = df[df.label==4]\n",
    "    if mode == \"undersampling\":\n",
    "        # upsample minority\n",
    "        class_3_downsampled = resample(class_3,\n",
    "                                  replace=True, # sample with replacement\n",
    "                                  n_samples=len(class_1), # match number in majority class\n",
    "                                  random_state=27) # reproducible results\n",
    "        return pd.concat([class_0,class_1,class_2,class_3_downsampled,class_4]) \n",
    "    else:\n",
    "        class_0_upsampled = resample(class_0,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/3), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_1_upsampled = resample(class_1,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/2), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_2_upsampled = resample(class_2,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/2), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_4_upsampled = resample(class_4,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/2), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        return pd.concat([class_0_upsampled, class_1_upsampled, class_2_upsampled, class_3, class_4_upsampled]) \n",
    "\n",
    "    \n",
    "if params[\"balance_data\"]:\n",
    "#     train_folds = balance_data(train_folds, mode=\"undersampling\")    \n",
    "    train_folds = balance_data(train_folds, mode=\"oversamling\")\n",
    "    visualize_class_dis(train_folds, f'fold {fold} after balance data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EtOPkNwh5-8"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, mosaic_mix = False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transform = transform\n",
    "        self.mosaic_mix = mosaic_mix\n",
    "        self.rand_aug_fn = RandAugment()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{root}/train_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        if params[\"rand_aug\"]:\n",
    "            image = np.array(self.rand_aug_fn(Image.fromarray(image)))\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label, file_name\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, valid_test=False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        self.valid_test = valid_test\n",
    "        if self.valid_test:\n",
    "            self.labels = df['label'].values  \n",
    "        else:\n",
    "            assert ValueError(\"Test data does not have annotation, plz check!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        if self.valid_test:\n",
    "            file_path = f'{root}/train_images/{file_name}'\n",
    "            #file_path = f'{root}/external/extraimages/{file_name}'\n",
    "        else:\n",
    "            file_path = f'{root}/test_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isinstance(self.transform, list):\n",
    "            outputs = {'images':[],\n",
    "                       'labels':[],\n",
    "                       'image_id':[]}            \n",
    "             #image0 = transforms.ToPILImage()(image)\n",
    "             #image0 = self.transform[0](image0)\n",
    "\n",
    "            for trans in self.transform:\n",
    "                augmented = trans(image=image)\n",
    "                image_aug = augmented['image']\n",
    "                outputs[\"images\"].append(image_aug)\n",
    "                del image_aug\n",
    "                \n",
    "            if self.valid_test:\n",
    "                label = torch.tensor(self.labels[idx]).long()\n",
    "                outputs['labels'] = len(self.transform)*[label]\n",
    "                outputs['image_ids'].append(file_name)\n",
    "                \n",
    "            else:\n",
    "                outputs['labels'] = len(self.transform)*[-1]\n",
    "                \n",
    "            return outputs\n",
    "        else:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image'] \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Albumentations to define transformation functions for the train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm_NP-c4h5-_"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "        A.OneOf([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),]\n",
    "        ),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.IAAAffine(rotate=0.2, shear=0.2,p=0.5),\n",
    "        A.CoarseDropout(max_holes=20, max_height=10, max_width=10, p=0.5),\n",
    "        A.IAAAdditiveGaussianNoise(p=0.5),\n",
    "        A.MotionBlur(p=0.5),\n",
    "        A.HueSaturationValue(p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(params[\"image_size\"],params[\"image_size\"]),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "if params[\"cutmix\"]:\n",
    "    mixup_fn = Mixup(mixup_alpha=1., cutmix_alpha=1, label_smoothing=0.1, num_classes=params[\"num_classes\"])\n",
    "else:\n",
    "    mixup_fn = Mixup(mixup_alpha=1., label_smoothing=0.1, num_classes=params[\"num_classes\"])\n",
    "\n",
    "train_dataset = TrainDataset(train_folds, transform=train_transform)\n",
    "val_dataset = TrainDataset(val_folds, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's define a function that takes a dataset and visualizes different augmentations applied to the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, idx=0, samples=10, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(samples):\n",
    "        image, _, _ = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"visualize\"]:\n",
    "    random.seed(SEED)\n",
    "    visualize_augmentations(train_dataset, idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Mixup CutMix Aug\n",
    "def visualize_mix_augmentations(dataset, idx=[1,2,3,4], cols=4):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    rows = 1\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 15))\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in idx:\n",
    "        image, label, _ = dataset[i]\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        \n",
    "    images, labels = mixup_fn(torch.stack(images).cuda(), torch.stack(labels).float().cuda())\n",
    "    for i, (image,label) in enumerate(zip(images, labels)):\n",
    "        unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        image = (unorm(image).cpu().numpy()*255).astype(int)\n",
    "        ax.ravel()[i].imshow(image.transpose(1,2,0))\n",
    "        ax.ravel()[i].set_title(label.argmax(), color='GREEN')\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"visualize\"] and params[\"mix_up\"]:\n",
    "    random.seed(SEED)\n",
    "    visualize_mix_augmentations(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helpers for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a few helpers for our training pipeline. `calculate_accuracy` takes model predictions and true labels and will return accuracy for those predictions. `MetricMonitor` helps to track metrics such as accuracy or loss during training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgTqE0eYSjDh"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, target):\n",
    "#     return torch.true_divide((target == output).sum(dim=0), output.size(0)).item()\n",
    "    if params[\"mix_up\"]:\n",
    "        output = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "        return accuracy_score(output.cpu(), target.argmax(1).cpu())\n",
    "    \n",
    "    output = torch.softmax(output, dim=1)\n",
    "    return accuracy_score(output.argmax(1).cpu(), target.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRhPJiCch5_D"
   },
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "        self.curr_acc = 0.\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "        self.curr_acc = metric[\"avg\"]\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"hard_negative_sample\"]:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hard_sample(train_loader, model, val_criterion, thres):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    train_loss_list = {'image_id':[],\n",
    "                       'label':[],\n",
    "                       'loss':[],\n",
    "                       'fold':[]}\n",
    "    model.eval()\n",
    "    stream = tqdm(train_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target, name) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True)#.view(-1,params['batch_size'])\n",
    "            output = model(images)\n",
    "            loss = val_criterion(output, target)\n",
    "            if loss > thres:\n",
    "                train_loss_list['image_id'].append(name[0])\n",
    "                train_loss_list['label'].append(int(target[0].cpu().numpy()))\n",
    "                train_loss_list['loss'].append(loss)\n",
    "                train_loss_list['fold'].append(params['fold'])\n",
    "    print(\"Number hard samples:\",len(train_loss_list[\"loss\"]))\n",
    "    #visualize\n",
    "    ax.ravel()[0].plot(train_loss_list['loss'])\n",
    "    ax.ravel()[0].set_title(\"Loss\", color='BLUE')\n",
    "    #ax.ravel()[0].set_axis_off() \n",
    "    \n",
    "    ax.ravel()[1].plot(sorted(train_loss_list['loss']))\n",
    "    ax.ravel()[1].set_title(\"Sort Curve\", color='BLUE')\n",
    "    #ax.ravel()[1].set_axis_off() \n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "        \n",
    "    return dict(image_id=train_loss_list['image_id'],\n",
    "                label=train_loss_list['label'],\n",
    "                fold=train_loss_list['fold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a few training parameters such as model architecture, learning rate, batch size, epochs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "        params[\"model\"],\n",
    "        pretrained=True,\n",
    "        num_classes=params[\"num_classes\"],\n",
    "        drop_block_rate=params[\"drop_block\"],\n",
    "        drop_rate=params[\"drop\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(n_features, params['num_classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all required objects and functions for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7HipbJ8h5_I"
   },
   "outputs": [],
   "source": [
    "# model = getattr(models, params[\"model\"])(pretrained=False, num_classes=5)\n",
    "model = model.to(params[\"device\"])\n",
    "val_criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "# criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "criterion = LabelSmoothingCrossEntropy().to(params[\"device\"])\n",
    "if params[\"mix_up\"]:\n",
    "    criterion = SoftTargetCrossEntropy().to(params[\"device\"])\n",
    "    \n",
    "if params[\"distributed\"]:\n",
    "    assert ValueError(\"No need to implement in a single machine\")\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)    \n",
    "if params[\"load_pretrained\"]:\n",
    "    state_dict = torch.load(weights[ckpt_index])\n",
    "    print(\"Load pretrained model: \",state_dict[\"preds\"])\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    best_acc = state_dict[\"preds\"]\n",
    "    # Hard negative mining based on train data and pretrained model on that data\n",
    "    if params[\"hard_negative_sample\"]:\n",
    "        update_train_data = update_hard_sample(train_loader, model, val_criterion, thres=0.2)\n",
    "        update_train_folds = pd.DataFrame(data=update_train_data)\n",
    "        \n",
    "        #check the update distribution when filter data\n",
    "        print(\"Class distribution for the new data\")\n",
    "        visualize_class_dis(update_train_folds, params[\"fold\"])\n",
    "        \n",
    "        #update the training set\n",
    "        update_train_dataset = TrainDataset(update_train_folds, transform=train_transform)\n",
    "        update_train_loader = DataLoader(\n",
    "            update_train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "        )                \n",
    "else:\n",
    "    best_acc = 0.\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"])\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=params[\"lr_min\"], last_epoch=-1)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=params[\"lr_min\"], last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNz-5F7Bh5_Y"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    if params[\"hard_negative_sample\"]:\n",
    "        stream = tqdm(update_train_loader)\n",
    "    else:\n",
    "        stream = tqdm(train_loader)\n",
    "    for i, (images, target, _) in enumerate(stream, start=1):\n",
    "        images = images.to(params[\"device\"]) #, non_blocking=True)\n",
    "        target = target.to(params[\"device\"]) #, non_blocking=True) #.view(-1,params['batch_size'])\n",
    "        if params[\"mix_up\"]:\n",
    "            images , target = mixup_fn(images, target)\n",
    "        output = model(images)\n",
    "        if isinstance(output, (tuple, list)):\n",
    "            output = output[0]\n",
    "        loss = criterion(output, target)\n",
    "        if params['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / params['gradient_accumulation_steps']\n",
    "    \n",
    "        accuracy = calculate_accuracy(output, target)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chKMqryvh5_a"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch, params, fold, best_acc):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target, _) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True)#.view(-1,params['batch_size'])\n",
    "            output = model(images)\n",
    "            loss = val_criterion(output, target)\n",
    "            output = torch.softmax(output, dim = 1)\n",
    "            \n",
    "            accuracy = accuracy_score(output.argmax(1).cpu(), target.cpu())\n",
    "\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )           \n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        #to save weight\n",
    "        if (metric_monitor.curr_acc > best_acc): # or epoch == params[\"epochs\"]:\n",
    "            print(f\"Save best weight at acc {round(metric_monitor.curr_acc,4)}, epoch: {epoch}\")\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                'preds': round(metric_monitor.curr_acc,4)},\n",
    "                 f'weights/{params[\"model\"]}_fold{fold}_best_epoch_{epoch}.pth')\n",
    "\n",
    "            best_acc = metric_monitor.curr_acc\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "IiA5Zgfch5_c",
    "outputId": "f4fba281-0997-4202-e9d2-6aa3f93373f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 1.007 | Accuracy: 0.702:  54%|█████▍    | 289/535 [00:46<00:39,  6.28it/s]"
     ]
    }
   ],
   "source": [
    "if params[\"train_phase\"]:\n",
    "    for epoch in range(1, params[\"epochs\"] + 1):\n",
    "        train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "        best_acc = validate(val_loader, model, criterion, epoch, params, fold, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model': model.state_dict(), \n",
    "#     'preds': 0.8},\n",
    "#      f'weights/{params[\"model\"]}_fold{fold}_best_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction and TTA on validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tta0 = A.Compose(\n",
    "    [\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "#      A.RandomCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_tta1 = A.Compose(\n",
    "    [\n",
    "#      A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "#      A.RandomCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),      \n",
    "     A.HorizontalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "transform_tta2 = A.Compose(\n",
    "    [\n",
    "#      A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "#      A.RandomCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.VerticalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "transform_tta3 = A.Compose(\n",
    "    [\n",
    "#      A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "#      A.RandomCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.RandomRotate90(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),     \n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "transform_tta4 = transforms.Compose(\n",
    "    [\n",
    "     transforms.FiveCrop(params[\"image_size\"]), # this is a list of PIL Images\n",
    "     transforms.Lambda(lambda crops: torch.stack([ToTensorV2()(crop) for crop in crops])),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), \n",
    "    ]\n",
    ")\n",
    "test_transform_tta = [transform_tta0, transform_tta1, transform_tta2, transform_tta3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"tta\"]:\n",
    "    val_pred_dataset = TestDataset(val_folds, transform=test_transform_tta, valid_test=True)\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta)\n",
    "else:\n",
    "    val_pred_dataset = TestDataset(val_folds, transform=val_transform, valid_test=True)\n",
    "    test_pred_dataset = TestDataset(test, transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_loader = DataLoader(\n",
    "    val_pred_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=2, pin_memory=True,\n",
    ")\n",
    "test_pred_loader = DataLoader(\n",
    "    test_pred_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=2, pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tta(data, pred):     \n",
    "    unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    if params[\"tta\"]:\n",
    "        figure, ax = plt.subplots(nrows=1, ncols=num_tta, figsize=(12, 6))\n",
    "        for i, image in enumerate(data[\"images\"]):\n",
    "            image = (unorm(image[0]).cpu().numpy()*255).astype(int)\n",
    "            ax.ravel()[i].imshow(image.transpose(2,1,0))\n",
    "            ax.ravel()[i].set_title(str(pred), color='GREEN')\n",
    "            ax.ravel()[i].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    else:\n",
    "        image = (unorm(data).cpu().numpy()*255).astype(int)\n",
    "        imgplot = plt.imshow(image[0].transpose(2,1,0))\n",
    "        imgplot = plt.title(str(pred), color='GREEN')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tta = len(test_transform_tta)\n",
    "def tta_validate(loader, model, params, valid_test=False):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            if params[\"visualize\"]:\n",
    "                visualize_tta(data, pred)\n",
    "            tta_output = []   \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                tta_output.append(model(image))\n",
    "            tta_output = torch.stack(tta_output, dim=0).mean(dim=0)\n",
    "            output = torch.softmax(tta_output, dim=1)\n",
    "            accuracy = accuracy_score(output.argmax(1).cpu(), data[\"labels\"][0].cpu())\n",
    "                \n",
    "            metric_monitor.update(\"Accuracy\", accuracy)            \n",
    "            stream.set_description(\n",
    "                \"TTA Validation. {metric_monitor}\".format(metric_monitor=metric_monitor)\n",
    "            )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re test the validation accuracy with TTA\n",
    "tta_validate(val_pred_loader, model, params, valid_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tta = len(test_transform_tta)\n",
    "def predict(loader, model, params, valid_test=False):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    stream = tqdm(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            if params[\"tta\"]:\n",
    "                ## TTA output\n",
    "                tta_output = []   \n",
    "                for i, image in enumerate(data[\"images\"]):\n",
    "                    tta_output.append(model(image))\n",
    "                tta_output = torch.stack(tta_output, dim=0).mean(dim=0)\n",
    "                output = torch.softmax(tta_output, dim=1)\n",
    "            else:\n",
    "                data = data.to(params[\"device\"], non_blocking=True)\n",
    "                output = model(data)                               \n",
    "                output = torch.softmax(output, dim = 1)\n",
    "            pred = torch.argmax(output, dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            ## For visualize the TTA \n",
    "            if params[\"visualize\"]:\n",
    "                visualize_tta(data, pred)\n",
    "    return preds\n",
    "if not params[\"train_phase\"]:\n",
    "    preds = predict(test_pred_loader, model, params, valid_test=True)  \n",
    "    test['label']=preds\n",
    "    test.to_csv('submission.csv', index=False)\n",
    "    test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"tta\"] = True\n",
    "create_pseudo = False\n",
    "num_tta = len(test_transform_tta)\n",
    "def pseudo_predict(loader, model, params, valid_test=False):\n",
    "    preds = {'image_id':[],\n",
    "             'label': []}\n",
    "    model.eval()\n",
    "    stream = tqdm(loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            ## TTA output\n",
    "            tta_output = []   \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                tta_output.append(model(image))\n",
    "            tta_output = torch.stack(tta_output, dim=0).mean(dim=0)\n",
    "            output = torch.softmax(tta_output, dim=1)\n",
    "            pred = torch.argmax(output, dim=1).cpu().numpy()\n",
    "            for j,p in enumerate(pred):\n",
    "                if output[j][p] > 0.7:\n",
    "                    preds['image_id'].append(data[\"image_ids\"][0][j])\n",
    "                    preds['label'].append(p)\n",
    "    return preds\n",
    "if create_pseudo:\n",
    "    ## add external data\n",
    "    test_external_dataset = TestDataset(test_external, transform=test_transform_tta, valid_test=True)\n",
    "    test_external_loader = DataLoader(\n",
    "        test_external_dataset, batch_size=params['batch_size'], shuffle=False, num_workers=4, pin_memory=True,\n",
    "    )  \n",
    "    pred_test_external = pseudo_predict(test_external_loader, model, params, valid_test=True)\n",
    "    pseudo = pd.DataFrame(pred_test_external)\n",
    "    pseudo.to_csv(f'{root}/external/test_external_pseudo.csv' ,index=False)\n",
    "    visualize_class_dis(pseudo, 'external pseudo data')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification (1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "traffic_monitor",
   "language": "python",
   "name": "traffic_monitor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
