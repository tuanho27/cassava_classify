{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassava classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edyDFX_Ih5-j"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "cudnn.benchmark = True\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from utils import Mixup, RandAugment, AsymmetricLossSingleLabel, SCELoss, fmix\n",
    "from PIL import Image\n",
    "from torchcontrib.optim import SWA\n",
    "from apex import amp\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] =\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the root directory dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waXTuqeVh5-q"
   },
   "outputs": [],
   "source": [
    "root = os.path.join(os.environ[\"HOME\"], \"Workspace/datasets/taiyoyuden/cassava\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split files from the dataset into the train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some files in the dataset are broken, so we will use only those image files that OpenCV could load correctly. We will use 20000 images for training, 4936 images for validation, and 10 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgLoujrNHY5Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_images',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_1_pseudo.csv',\n",
       " 'val_1_pseudo.csv',\n",
       " 'external',\n",
       " 'sample_submission.csv',\n",
       " 'train_images',\n",
       " 'label_num_to_disease_map.json.save',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to visualize images and their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will take a list of images' file paths and their labels and visualize them in a grid. Correct labels are colored green, and incorrectly predicted labels are colored red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4\n",
       "1  1000015157.jpg      0\n",
       "2  1000201771.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "train_external = pd.read_csv(f'{root}/external/train_external.csv')\n",
    "test_external = pd.read_csv(f'{root}/external/test_external.csv')\n",
    "test_external_pseudo = pd.read_csv(f'{root}/external/test_external_pseudo_0.8_round2.csv')\n",
    "test = pd.read_csv(f'{root}/sample_submission.csv')\n",
    "label_map = pd.read_json(f'{root}/label_num_to_disease_map.json', \n",
    "                         orient='index')\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7320,  910, 5440, 5241, 5784, 6315,  516, 4476, 5628, 8372, 1735,\n",
       "        819, 6999, 2483, 5361, 5101, 6470, 1234, 4605, 3435, 6446, 8716,\n",
       "       9324, 2608, 7899, 2097, 2797, 9217,  239, 2784, 3055, 4708, 1949,\n",
       "       7784, 1317, 1578, 3606, 3940, 8888, 5443, 8842, 8483, 7563, 2662,\n",
       "       7091, 9605, 6285, 5536, 7149, 9720])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map.iloc[1].values\n",
    "np.random.randint(50, 10000, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ho-BaziAHY5q"
   },
   "outputs": [],
   "source": [
    "def visualize_input_image_grid(filepaths, image_name, labels, cols=4):\n",
    "    rows = 5\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(25, 15))\n",
    "    for i, index in enumerate(np.random.randint(0, len(image_name), 20)):\n",
    "        name = image_name.iloc[index]['image_id']\n",
    "        label =  image_name.iloc[index]['label']\n",
    "        image = cv2.imread(f'{filepaths}/train_images/{name}')\n",
    "        if (i == 0): \n",
    "            print(image.shape)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_title(label, color='GREEN')\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the parameters of the whole process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = [\"resnest26d\",\"resnest50d\",\"tf_efficientnet_b4_ns\", \"legacy_seresnext26_32x4d\", \"skresnet34\" ,\"cspresnext50\",\n",
    "               \"vit_base_patch16_384\", \"legacy_seresnet50\"]\n",
    "WEIGHTS = [\n",
    "#     \"weights/resnest26d/resnest26d_fold0_best_epoch_28_final_1st.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold0_best_epoch_13_final_mixup.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold2_best_epoch_3_final_hnm.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_29_1st.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_26_mix.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_12_cutmix.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_3_external.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_21_final_512.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold3_best_epoch_10_final_3rd.pth\",\n",
    "#     \"weights/resnest26d/resnest26d_fold4_best_epoch_6_final_3rd.pth\",\n",
    "    \n",
    "#     \"weights/tf_efficientnet_b3_ns/tf_efficientnet_b3_ns_fold1_best_epoch_19_external.pth\",\n",
    "#     \"weights/tf_efficientnet_b3_ns/tf_efficientnet_b3_ns_fold1_best_epoch_26_512.pth\",\n",
    "#     \"weights/tf_efficientnet_b3_ns/tf_efficientnet_b3_ns_fold1_best_epoch_1_final_512.pth\",\n",
    "    \n",
    "#     \"weights/resnest50d/resnest50d_fold1_best_epoch_95_final_1st.pth\",\n",
    "# #     \"weights/resnest50d/resnest50d_fold1_best_epoch_9_final_512.pth\"\n",
    "#     \"weights/resnest50d/resnest50d_fold1_best_epoch_38_clean_1st.pth\",\n",
    "#     \"weights/resnest50d/resnest50d_fold0_best_epoch_25.pth\",\n",
    "#     \"./weights/resnest50d/resnest50d_fold2_best_epoch_50_final_1st.pth\",\n",
    "#     \"./weights/resnest50d/resnest50d_fold4_best_epoch_39.pth\",\n",
    "#     \"weights/resnest50d/resnest50d_fold1_best_epoch_95_final_1st.pth\",\n",
    "#     \"./weights/resnest50d/resnest50d_fold1_best_epoch_17_final_2nd.pth\",\n",
    "#     \"./weights/resnest50d/resnest50d_fold3_best_epoch_2_final_2nd.pth\",\n",
    "#     \"./weights/resnest50d/resnest50d_fold0_best_epoch_13_final_2nd.pth\",\n",
    "    \n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold0_best_epoch_84_final_1st.pth\",\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold0_best_epoch_24_final_2nd.pth\",\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold1_best_epoch_65_final_1st.pth\",\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold1_best_epoch_20_final_2nd.pth\",\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold1_best_epoch_30_final_3rd.pth\",\n",
    "#     \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold2_best_epoch_29_final_3rd.pth\"\n",
    "#     \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold3_best_epoch_16_final_3rd.pth\"\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold2_best_epoch_82_final_1st.pth\",\n",
    "#         \"weights/tf_efficientnet_b4_ns/tf_efficientnet_b4_ns_fold2_best_epoch_20_final_2nd.pth\",\n",
    "    \n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold0_best_epoch_75_final_1st.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold0_best_epoch_22_final_2nd.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold1_best_epoch_80_final_1st.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold1_best_epoch_32_final_2nd.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold1_best_epoch_30_final_3rd.pth\"\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold2_best_epoch_92_final_1st.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold2_best_epoch_28_final_2nd.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold3_best_epoch_9_final_3rd.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold4_best_epoch_16_final_3rd.pth\"\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold0_best_epoch_29_final_4th.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold1_best_epoch_17_final_4th.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold2_best_epoch_28_final_4th.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold3_best_epoch_14_final_4th.pth\",\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold3_best_epoch_4_final_5th.pth\"\n",
    "#     \"weights/legacy_seresnext26_32x4d/legacy_seresnext26_32x4d_fold4_best_epoch_27_final_4th.pth\"\n",
    "    \"weights/legacy_seresnet50/legacy_seresnet50_fold0_best_epoch_80.pth\",\n",
    "    \"weights/legacy_seresnet50/legacy_seresnet50_fold0_best_epoch_27_final_2nd.pth\",\n",
    "    \"weights/legacy_seresnet50/legacy_seresnet50_fold2_best_epoch_98.pth\"\n",
    "    \n",
    "]\n",
    "model_index = -1\n",
    "ckpt_index = -1\n",
    "fold_ckpt_index = [11,12]\n",
    "fold_ckpt_weight = [1,1]\n",
    "\n",
    "params = {\n",
    "    \"visualize\": False,\n",
    "    \"fold\": 3,\n",
    "    \"distill_soft_label\":False,\n",
    "    \"train_external\": False,\n",
    "    \"train_clean_only\": False,\n",
    "    \"test_external\": False,\n",
    "    \"load_pretrained\": False,\n",
    "    \"fp16\": False,\n",
    "    \"resume\": False,\n",
    "    \"image_size\": 256,\n",
    "    \"num_classes\": 5,\n",
    "    \"model\": models_name[model_index],\n",
    "    \"device\": \"cuda\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_min\":1e-8,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 8,\n",
    "    \"epochs\": 100,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"drop_block\": 0.2,\n",
    "    \"drop_rate\": 0.2,\n",
    "    \"mix_up\": True,\n",
    "    \"cutmix\":False,\n",
    "    \"fmix\":False,\n",
    "    \"fmix_epoch\":10,\n",
    "    \"smooth_label\": 0.1,\n",
    "    \"rand_aug\": False,\n",
    "    \"local_rank\":0,\n",
    "    \"distributed\": False,\n",
    "    \"hard_negative_sample\": False,\n",
    "    \"tta\": True,\n",
    "    \"train_phase\":True,\n",
    "    \"balance_data\":False,\n",
    "    \"kfold_pred\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset with KFolds strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let visualize the dataset with the defined class, the proceed the split dataset with 5 folds\n",
    "Then, we can add the external dataset to each fold and visualize the class distribution of the dataset\n",
    "\n",
    "The class dataset is defined with transform and random augmentation.\n",
    "\n",
    "`__init__` will receive an optional `transform` argument. It is a transformation function of the Albumentations augmentation pipeline. Then in `__getitem__`, the Dataset class will use that function to augment an image and return it along with the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['visualize']:\n",
    "    visualize_input_image_grid(root, train, label_map)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  label\n",
      "0     0         218\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2631\n",
      "      4         516\n",
      "1     0         218\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2631\n",
      "      4         516\n",
      "2     0         217\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2632\n",
      "      4         515\n",
      "3     0         217\n",
      "      1         438\n",
      "      2         477\n",
      "      3        2632\n",
      "      4         515\n",
      "4     0         217\n",
      "      1         437\n",
      "      2         478\n",
      "      3        2632\n",
      "      4         515\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['label'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold','label']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000837476.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  fold\n",
       "0      1000201771.jpg      3     2\n",
       "1       100042118.jpg      1     2\n",
       "2      1000723321.jpg      1     1\n",
       "3      1000812911.jpg      3     2\n",
       "4      1000837476.jpg      3     2\n",
       "...               ...    ...   ...\n",
       "17113   999068805.jpg      3     1\n",
       "17114   999329392.jpg      3     0\n",
       "17115   999474432.jpg      1     1\n",
       "17116   999616605.jpg      4     2\n",
       "17117   999998473.jpg      4     4\n",
       "\n",
       "[17118 rows x 3 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = params[\"fold\"]\n",
    "train_idx = folds[folds['fold'] != fold].index\n",
    "val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "train_folds = folds.loc[train_idx].reset_index(drop=True)\n",
    "val_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-cbsd-663.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-cgm-560.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cmd-1576.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-cbb-443.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-cgm-293.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>train-cmd-1383.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>train-cmd-971.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>train-cbb-402.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5654</th>\n",
       "      <td>train-cbsd-1029.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>train-cmd-2291.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id  label  fold\n",
       "0      train-cbsd-663.jpg      1     3\n",
       "1       train-cgm-560.jpg      2     3\n",
       "2      train-cmd-1576.jpg      3     3\n",
       "3       train-cbb-443.jpg      0     3\n",
       "4       train-cgm-293.jpg      2     3\n",
       "...                   ...    ...   ...\n",
       "5651   train-cmd-1383.jpg      3     3\n",
       "5652    train-cmd-971.jpg      3     3\n",
       "5653    train-cbb-402.jpg      0     3\n",
       "5654  train-cbsd-1029.jpg      1     3\n",
       "5655   train-cmd-2291.jpg      3     3\n",
       "\n",
       "[5656 rows x 3 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_external\n",
    "for idx,label in enumerate(train_external['label']):\n",
    "    train_external.loc[idx,'fold'] = fold\n",
    "train_external['fold'] = train_external['fold'].astype(int)\n",
    "train_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df1, df2):\n",
    "    merge_df = pd.concat([df1, df2], axis=0) #,how ='outer', on ='image_id')\n",
    "    return merge_df\n",
    "\n",
    "if params[\"train_external\"]:\n",
    "    train_folds = merge_data(train_folds, train_external)\n",
    "if params[\"train_clean_only\"]:\n",
    "    train_folds = train_external\n",
    "#     train_folds = pd.read_csv(f'{root}/train_{params[\"fold\"]}_pseudo.csv')\n",
    "#     val_folds = pd.read_csv(f'{root}/val_{params[\"fold\"]}_pseudo.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000837476.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  fold\n",
       "0      1000201771.jpg      3     2\n",
       "1       100042118.jpg      1     2\n",
       "2      1000723321.jpg      1     1\n",
       "3      1000812911.jpg      3     2\n",
       "4      1000837476.jpg      3     2\n",
       "...               ...    ...   ...\n",
       "17113   999068805.jpg      3     1\n",
       "17114   999329392.jpg      3     0\n",
       "17115   999474432.jpg      1     1\n",
       "17116   999616605.jpg      4     2\n",
       "17117   999998473.jpg      4     4\n",
       "\n",
       "[17118 rows x 3 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     1087\n",
      "1     2189\n",
      "2     2386\n",
      "3    13158\n",
      "4     2577\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     466\n",
      "1    1443\n",
      "2     773\n",
      "3    2658\n",
      "4     316\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0      870\n",
      "1     1751\n",
      "2     1909\n",
      "3    10526\n",
      "4     2062\n",
      "Name: image_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_class_dis(df, fold, color='maroon'):\n",
    "    x = df.groupby('label').count()\n",
    "    print(x['image_id'])\n",
    "    y = [0,1,2,3,4]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.bar(y, x['image_id'].values, color =color, width = 0.4)\n",
    "    plt.xlabel(\"Label\") \n",
    "    plt.ylabel(\"Number of image\") \n",
    "    plt.title(f\"Class distribution of data fold: {fold}\") \n",
    "\n",
    "    # plt.xticks(x['image_id'])\n",
    "    plt.show()\n",
    "visualize_class_dis(train, 'all data', color='blue')\n",
    "visualize_class_dis(train_external, 'external data', color='purple')\n",
    "visualize_class_dis(train_folds, params['fold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000837476.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17113</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17114</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17115</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17116</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17117</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label  fold\n",
       "0      1000201771.jpg      3     2\n",
       "1       100042118.jpg      1     2\n",
       "2      1000723321.jpg      1     1\n",
       "3      1000812911.jpg      3     2\n",
       "4      1000837476.jpg      3     2\n",
       "...               ...    ...   ...\n",
       "17113   999068805.jpg      3     1\n",
       "17114   999329392.jpg      3     0\n",
       "17115   999474432.jpg      1     1\n",
       "17116   999616605.jpg      4     2\n",
       "17117   999998473.jpg      4     4\n",
       "\n",
       "[17118 rows x 3 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if params[\"test_external\"]:\n",
    "    train_folds = merge_data(train_folds, test_external_pseudo)\n",
    "    visualize_class_dis(train_folds, f'fold {fold} add extra pseudo test external data')\n",
    "train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(df, mode=\"undersampling\", val=False):\n",
    "    class_0 = df[df.label==0]\n",
    "    class_1 = df[df.label==1]\n",
    "    class_2 = df[df.label==2]\n",
    "    class_3 = df[df.label==3]\n",
    "    class_4 = df[df.label==4]\n",
    "    if mode == \"undersampling\":\n",
    "        # upsample minority\n",
    "        class_3_downsampled = resample(class_3,\n",
    "                                  replace=True, # sample with replacement\n",
    "                                  n_samples=int(len(class_3)*2/3), # match number in majority class\n",
    "                                  random_state=27) # reproducible results\n",
    "        if val:\n",
    "            return  pd.concat([class_0, class_1, class_2, class_3_downsampled, class_4]) \n",
    "    \n",
    "        class_1_downsampled = resample(class_1,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_1)*0.7), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_4_upsampled = resample(class_4,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_4)*1.3), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        return pd.concat([class_0, class_1_downsampled, class_2, class_3_downsampled, class_4_upsampled]) \n",
    "    else:\n",
    "        class_0_upsampled = resample(class_0,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/4), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_1_upsampled = resample(class_1,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/3), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_2_upsampled = resample(class_2,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/3), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        class_4_upsampled = resample(class_4,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=int(len(class_3)/3), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "        return pd.concat([class_0_upsampled, class_1_upsampled, class_2_upsampled, class_3, class_4_upsampled]) \n",
    "\n",
    "    \n",
    "if params[\"balance_data\"]:\n",
    "    train_folds = balance_data(train_folds, mode=\"undersampling\")    \n",
    "    val_folds = balance_data(val_folds, mode=\"undersampling\", val=True)    \n",
    "    \n",
    "#     train_folds = balance_data(train_folds, mode=\"oversamling\")\n",
    "    visualize_class_dis(train_folds, f'fold {fold} after balance data')\n",
    "    visualize_class_dis(val_folds, f'fold {fold} after balance data')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for distillation using soft label    \n",
    "if params[\"distill_soft_label\"]:\n",
    "    soft_target_list = set(list([0,1,2,3,4])) - set([params[\"fold\"]])\n",
    "    print(soft_target_list)\n",
    "    for k, f in enumerate(soft_target_list):\n",
    "        if k == 0:\n",
    "#             soft_target_distill = pd.read_csv(f'./error_analysis/val_{params[\"model\"]}_{f}_pred.csv')\n",
    "            soft_target_distill = pd.read_csv(f'./error_analysis/val_resnest50d_{f}_pred.csv')\n",
    "            \n",
    "        else:\n",
    "#             soft_target_distill = merge_data(soft_target_distill,  pd.read_csv(f'./error_analysis/val_{params[\"model\"]}_{f}_pred.csv'))\n",
    "            soft_target_distill = merge_data(soft_target_distill,  pd.read_csv(f'./error_analysis/val_resnest50d_{f}_pred.csv'))\n",
    "\n",
    "    soft_target_distill = soft_target_distill.reset_index(drop=True)\n",
    "    print(soft_target_distill.set_index('image_id').sort_index())\n",
    "    soft_target_distill = soft_target_distill.set_index('image_id').sort_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EtOPkNwh5-8"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, mosaic_mix = False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transform = transform\n",
    "        self.mosaic_mix = mosaic_mix\n",
    "        self.rand_aug_fn = RandAugment()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{root}/train_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        if params[\"rand_aug\"]:\n",
    "            image = np.array(self.rand_aug_fn(Image.fromarray(image)))\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, label, file_name\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, valid_test=False, fcrops=False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        self.valid_test = valid_test\n",
    "        self.fcrops = fcrops\n",
    "        if self.valid_test:\n",
    "            self.labels = df['label'].values  \n",
    "        else:\n",
    "            assert ValueError(\"Test data does not have annotation, plz check!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        if self.valid_test:\n",
    "            file_path = f'{root}/train_images/{file_name}'\n",
    "            #file_path = f'{root}/external/extraimages/{file_name}'\n",
    "        else:\n",
    "            file_path = f'{root}/test_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isinstance(self.transform, list):\n",
    "            outputs = {'images':[],\n",
    "                       'labels':[],\n",
    "                       'image_ids':[]}\n",
    "            if self.fcrops:\n",
    "                for trans in self.transform:\n",
    "                    image_aug = transforms.ToPILImage()(image)\n",
    "                    image_aug = trans(image_aug)\n",
    "                    outputs[\"images\"].append(image_aug)\n",
    "                    del image_aug\n",
    "            else:\n",
    "                for trans in self.transform:\n",
    "                    augmented = trans(image=image)\n",
    "                    image_aug = augmented['image']\n",
    "                    outputs[\"images\"].append(image_aug)\n",
    "                    del image_aug\n",
    "\n",
    "            if self.valid_test:\n",
    "                label = torch.tensor(self.labels[idx]).long()\n",
    "                outputs['labels'] = len(self.transform)*[label]\n",
    "                outputs['image_ids'].append(file_name)\n",
    "                \n",
    "            else:\n",
    "                outputs['labels'] = len(self.transform)*[-1]\n",
    "                \n",
    "            return outputs\n",
    "        else:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image'] \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftTrainDataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None, soft_df = None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.labels = df['label'].values\n",
    "        self.transform = transform\n",
    "        self.rand_aug_fn = None #RandAugment()\n",
    "        self.distill_soft_target = soft_df \n",
    "        print(soft_df)\n",
    "        self.root = root\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{self.root}/train_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        if self.rand_aug_fn is not None:\n",
    "            image = np.array(self.rand_aug_fn(Image.fromarray(image)))\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        if self.distill_soft_target is not None:\n",
    "            soft_label = [float(t) for t in soft_target_distill[idx][0].split(\" \")]\n",
    "            soft_label = torch.tensor(soft_label)\n",
    "#             try:\n",
    "#                 soft_label = [float(t) for t in soft_target_distill[idx][0].split(\" \")]\n",
    "#                 soft_label = torch.tensor(soft_label)\n",
    "#             except:\n",
    "#                 soft_label = torch.tensor([0., 0., 0., 0., 0.])\n",
    "        else:\n",
    "            soft_label = 0.\n",
    "        return image, label, soft_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Albumentations to define transformation functions for the train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm_NP-c4h5-_"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "        A.OneOf([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),], p=1.\n",
    "        ),\n",
    "#         A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.IAAAffine(rotate=0.2, shear=0.2,p=0.5),\n",
    "        A.CoarseDropout(max_holes=20, max_height=int(params[\"image_size\"]/15), max_width=int(params[\"image_size\"]/15), p=0.5),\n",
    "#         A.IAAAdditiveGaussianNoise(p=1.),\n",
    "        A.MedianBlur(p=0.5),\n",
    "        A.Equalize(p=0.2),\n",
    "        A.GridDistortion(p=0.2),\n",
    "#         A.RandomGridShuffle(grid=(100, 100), p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "        A.Resize(params[\"image_size\"],params[\"image_size\"]),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "if params[\"cutmix\"]:\n",
    "    mixup_fn = Mixup(mixup_alpha=1., cutmix_alpha=1., label_smoothing=params[\"smooth_label\"], num_classes=params[\"num_classes\"])\n",
    "else:\n",
    "    mixup_fn = Mixup(mixup_alpha=1., label_smoothing=params[\"smooth_label\"], num_classes=params[\"num_classes\"])\n",
    "\n",
    "if params[\"distill_soft_label\"]:\n",
    "    train_dataset = SoftTrainDataset(train_folds, root, transform=train_transform, soft_df=soft_target_distill)\n",
    "else:\n",
    "    train_dataset = TrainDataset(train_folds, transform=train_transform)\n",
    "\n",
    "val_dataset = TrainDataset(val_folds, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also let's define a function that takes a dataset and visualizes different augmentations applied to the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, idx=3, samples=10, cols=5):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n",
    "    rows = samples // cols\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i in range(samples):\n",
    "        image, _, _ = dataset[idx]\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"visualize\"]:\n",
    "    random.seed(SEED)\n",
    "    visualize_augmentations(train_dataset, idx=random.randint(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Mixup CutMix Aug\n",
    "def visualize_mix_augmentations(dataset, idx=[4,5,1000,3], cols=4):\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    rows = 1\n",
    "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(20, 15))\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in idx:\n",
    "        image, label, _ = dataset[i]\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        \n",
    "    images, labels = mixup_fn(torch.stack(images).cuda(), torch.stack(labels).float().cuda())\n",
    "    for i, (image,label) in enumerate(zip(images, labels)):\n",
    "        unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        image = (unorm(image).cpu().numpy()*255).astype(int)\n",
    "        ax.ravel()[i].imshow(image.transpose(1,2,0))\n",
    "        ax.ravel()[i].set_title(label, color='GREEN')\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"visualize\"] and params[\"mix_up\"]:\n",
    "    random.seed(SEED)\n",
    "    visualize_mix_augmentations(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helpers for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a few helpers for our training pipeline. `calculate_accuracy` takes model predictions and true labels and will return accuracy for those predictions. `MetricMonitor` helps to track metrics such as accuracy or loss during training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgTqE0eYSjDh"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, target):\n",
    "#     return torch.true_divide((target == output).sum(dim=0), output.size(0)).item()\n",
    "    if params[\"mix_up\"]:\n",
    "        output = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "#         return accuracy_score(output.cpu(), target.argmax(1).cpu())\n",
    "        return accuracy_score(output.cpu(), target.cpu())\n",
    "    \n",
    "    output = torch.softmax(output, dim=1)\n",
    "    return accuracy_score(output.argmax(1).cpu(), target.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRhPJiCch5_D"
   },
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "        self.curr_acc = 0.\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "        self.curr_acc = metric[\"avg\"]\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"hard_negative_sample\"]:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "else:\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_hard_sample(train_loader, model, val_criterion, thres):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 6))\n",
    "    train_loss_list = {'image_id':[],\n",
    "                       'label':[],\n",
    "                       'loss':[],\n",
    "                       'fold':[]}\n",
    "    model.eval()\n",
    "    stream = tqdm(train_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target, name) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True)#.view(-1,params['batch_size'])\n",
    "            output = model(images)\n",
    "            loss = val_criterion(output, target)\n",
    "            if loss > thres:\n",
    "                train_loss_list['image_id'].append(name[0])\n",
    "                train_loss_list['label'].append(int(target[0].cpu().numpy()))\n",
    "                train_loss_list['loss'].append(loss)\n",
    "                train_loss_list['fold'].append(params['fold'])\n",
    "    print(\"Number hard samples:\",len(train_loss_list[\"loss\"]))\n",
    "    #visualize\n",
    "    ax.ravel()[0].plot(train_loss_list['loss'])\n",
    "    ax.ravel()[0].set_title(\"Loss\", color='BLUE')\n",
    "    #ax.ravel()[0].set_axis_off() \n",
    "    \n",
    "    ax.ravel()[1].plot(sorted(train_loss_list['loss']))\n",
    "    ax.ravel()[1].set_title(\"Sort Curve\", color='BLUE')\n",
    "    #ax.ravel()[1].set_axis_off() \n",
    "    \n",
    "    prob = 10 / (abs(sorted(train_loss_list['loss']) - sorted(train_loss_list['loss']).mean()) + 10)\n",
    "    ax.ravel()[2].plot(prob)\n",
    "    ax.ravel()[2].set_title(\"Sort reshape Curve\", color='GREEN')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "        \n",
    "    return dict(image_id=train_loss_list['image_id'],\n",
    "                label=train_loss_list['label'],\n",
    "                fold=train_loss_list['fold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a few training parameters such as model architecture, learning rate, batch size, epochs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"efficientnet\" in params[\"model\"]:\n",
    "    model = timm.create_model(\n",
    "            params[\"model\"],\n",
    "            pretrained=True,\n",
    "            num_classes=params[\"num_classes\"], \n",
    "            drop_rate=params[\"drop_rate\"], \n",
    "            drop_path_rate=0.3)\n",
    "    \n",
    "elif \"skresnet\" in params[\"model\"]:\n",
    "    model = timm.create_model(\n",
    "            params[\"model\"],\n",
    "            pretrained=True,\n",
    "            num_classes=params[\"num_classes\"],\n",
    "            drop_block_rate=params[\"drop_block\"],\n",
    "            drop_path_rate=0.2)\n",
    "else:\n",
    "    model = timm.create_model(\n",
    "            params[\"model\"],\n",
    "            pretrained=True,\n",
    "            num_classes=params[\"num_classes\"],\n",
    "            drop_rate=params[\"drop_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(n_features, params['num_classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all required objects and functions for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7HipbJ8h5_I"
   },
   "outputs": [],
   "source": [
    "# model = getattr(models, params[\"model\"])(pretrained=False, num_classes=5)\n",
    "model = model.to(params[\"device\"])\n",
    "val_criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "criterion_fmix = nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "criterion = LabelSmoothingCrossEntropy().to(params[\"device\"])\n",
    "if params[\"mix_up\"]:\n",
    "    criterion = SoftTargetCrossEntropy().to(params[\"device\"])\n",
    "asymetric_criterion = AsymmetricLossSingleLabel().to(params[\"device\"])\n",
    "symetric_criterion = SCELoss(smooth_label=params[\"smooth_label\"]).to(params[\"device\"])\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"lr\"])\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=params[\"lr_min\"], last_epoch=-1)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=params[\"lr_min\"], last_epoch=-1)\n",
    "\n",
    "if params[\"fp16\"]:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "\n",
    "if params[\"distributed\"]:\n",
    "    assert ValueError(\"No need to implement in a single machine\")\n",
    "else:\n",
    "    model = torch.nn.DataParallel(model)    \n",
    "if params[\"load_pretrained\"]:\n",
    "    state_dict = torch.load(WEIGHTS[ckpt_index])\n",
    "    print(\"Load pretrained model: \",state_dict[\"preds\"])\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    if params[\"resume\"]:\n",
    "        optimizer.load_state_dict(state_dict['optimizer'])\n",
    "        \n",
    "    if params[\"fp16\"]:\n",
    "        optimizer.load_state_dict(state_dict['optimizer'])\n",
    "        if params[\"resume\"]:\n",
    "            optimizer.load_state_dict(state_dict['optimizer'])\n",
    "\n",
    "        amp.load_state_dict(state_dict['amp'])\n",
    "\n",
    "    best_acc = state_dict[\"preds\"]\n",
    "    # Hard negative mining based on train data and pretrained model on that data\n",
    "    if params[\"hard_negative_sample\"]:\n",
    "        update_train_data = update_hard_sample(train_loader, model, val_criterion, thres=0.2)\n",
    "        update_train_folds = pd.DataFrame(data=update_train_data)\n",
    "        update_train_folds = pd.concat(5*[update_train_folds])\n",
    "        #check the update distribution when filter data\n",
    "        print(\"Class distribution for the new data\")\n",
    "        visualize_class_dis(update_train_folds, params[\"fold\"])\n",
    "        \n",
    "        #update the training set\n",
    "        update_train_dataset = TrainDataset(update_train_folds, transform=train_transform)\n",
    "        update_train_loader = DataLoader(\n",
    "            update_train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "        )                \n",
    "else:\n",
    "    print(\"Start train from scratch\")\n",
    "    best_acc = 0.83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNz-5F7Bh5_Y"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, criterion_fmix,optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    if params[\"hard_negative_sample\"]:\n",
    "        stream = tqdm(update_train_loader)\n",
    "    else:\n",
    "        stream = tqdm(train_loader)\n",
    "    for i, (images, target, _) in enumerate(stream, start=1):\n",
    "#         with autocast():\n",
    "        images = images.to(params[\"device\"]) #, non_blocking=True)\n",
    "        target = target.to(params[\"device\"]) #, non_blocking=True) #.view(-1,params['batch_size'])\n",
    "        if params[\"mix_up\"]:\n",
    "            images , mtarget = mixup_fn(images, target)\n",
    "            if params[\"distill_soft_label\"]:\n",
    "                mtarget = mtarget*0.7 + soft_target.to(params['device']) * 0.3\n",
    "        if epoch > params[\"fmix_epoch\"] and params[\"fmix\"]:\n",
    "            images , ftarget = fmix(images, target, alpha=1., decay_power=5.,\n",
    "                        shape=(params[\"image_size\"],params[\"image_size\"]),\n",
    "                        device=params[\"device\"])      \n",
    "            \n",
    "            \n",
    "        output = model(images)\n",
    "        if isinstance(output, (tuple, list)):\n",
    "            output = output[0]\n",
    "            \n",
    "        if epoch > params[\"fmix_epoch\"] and params[\"fmix\"]:\n",
    "            loss = criterion_fmix(output, ftarget[0]) * ftarget[2] + criterion_fmix(output, ftarget[1]) * (1. - ftarget[2])\n",
    "            \n",
    "        else:\n",
    "            loss = criterion(output, mtarget)\n",
    "            \n",
    "#         loss = criterion(output, target)\n",
    "            \n",
    "        if params['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / params['gradient_accumulation_steps']\n",
    "    \n",
    "        accuracy = calculate_accuracy(output, target)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        optimizer.zero_grad()\n",
    "        if params[\"fp16\"]:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chKMqryvh5_a"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch, params, fold, best_acc):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target, _) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True)#.view(-1,params['batch_size'])\n",
    "            output = model(images)\n",
    "            loss = val_criterion(output, target)\n",
    "            output = torch.softmax(output, dim = 1)\n",
    "            accuracy = accuracy_score(output.argmax(1).cpu(), target.cpu())\n",
    "\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )           \n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "            \n",
    "        #to save weight\n",
    "        if (metric_monitor.curr_acc > best_acc): # or epoch == params[\"epochs\"]:\n",
    "            print(f\"Save best weight at acc {round(metric_monitor.curr_acc,4)}, epoch: {epoch}\")\n",
    "            best_acc = metric_monitor.curr_acc\n",
    "            \n",
    "            directory = f'weights/{params[\"model\"]}'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            if params[\"fp16\"]:\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'amp': amp.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    'preds': round(metric_monitor.curr_acc,4)},\n",
    "                     f'weights/{params[\"model\"]}/{params[\"model\"]}_fold{fold}_best_epoch_{epoch}.pth')\n",
    "            else:\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                    'loss': loss,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'preds': round(metric_monitor.curr_acc,4)},\n",
    "                     f'weights/{params[\"model\"]}/{params[\"model\"]}_fold{fold}_best_epoch_{epoch}.pth')  \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/535 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 1.165 | Accuracy: 0.605: 100%|██████████| 535/535 [01:36<00:00,  5.55it/s]\n",
      "Epoch: 1. Validation. Loss: 0.973 | Accuracy: 0.628: 100%|██████████| 134/134 [00:07<00:00, 16.84it/s]\n",
      "Epoch: 2. Train.      Loss: 1.120 | Accuracy: 0.606: 100%|██████████| 535/535 [01:37<00:00,  5.51it/s]\n",
      "Epoch: 2. Validation. Loss: 1.008 | Accuracy: 0.656: 100%|██████████| 134/134 [00:08<00:00, 16.68it/s]\n",
      "Epoch: 3. Train.      Loss: 1.094 | Accuracy: 0.610: 100%|██████████| 535/535 [01:36<00:00,  5.54it/s]\n",
      "Epoch: 3. Validation. Loss: 0.811 | Accuracy: 0.734: 100%|██████████| 134/134 [00:08<00:00, 16.74it/s]\n",
      "Epoch: 4. Train.      Loss: 1.088 | Accuracy: 0.610:   7%|▋         | 35/535 [00:07<01:30,  5.54it/s]"
     ]
    }
   ],
   "source": [
    "print(f\"Train on fold: {fold}\")\n",
    "if params[\"train_phase\"]:\n",
    "    for epoch in range(1, params[\"epochs\"] + 1):\n",
    "        train(train_loader, model, criterion, criterion_fmix, optimizer, epoch, params)\n",
    "        best_acc = validate(val_loader, model, criterion, optimizer ,epoch, params, fold, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Train on fold: {fold}\")\n",
    "# if params[\"train_phase\"]:\n",
    "#     for epoch in range(1, params[\"epochs\"] + 1):\n",
    "#         train(train_loader, model, criterion, criterion_fmix, optimizer, epoch, params)\n",
    "#         best_acc = validate(val_loader, model, criterion, optimizer ,epoch, params, fold, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best_acc = 0\n",
    "# print(f\"Train on fold: {fold}\")\n",
    "# if params[\"train_phase\"]:\n",
    "#     for epoch in range(1, params[\"epochs\"] + 1):\n",
    "#         train(train_loader, model, criterion, criterion_fmix, optimizer, epoch, params)\n",
    "#         best_acc = validate(val_loader, model, criterion, optimizer ,epoch, params, fold, best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "IiA5Zgfch5_c",
    "outputId": "f4fba281-0997-4202-e9d2-6aa3f93373f0"
   },
   "outputs": [],
   "source": [
    "# # best_acc = 0\n",
    "# print(f\"Train on fold: {fold}\")\n",
    "# if params[\"train_phase\"]:\n",
    "#     for epoch in range(1, params[\"epochs\"] + 1):\n",
    "#         train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "#         best_acc = validate(val_loader, model, criterion, optimizer ,epoch, params, fold, best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model': model.state_dict(), \n",
    "#     'loss': 0.487,\n",
    "#     'optimizer': optimizer.state_dict(),\n",
    "#     'preds': 0.888},\n",
    "#      f'weights/{params[\"model\"]}/{params[\"model\"]}_fold{fold}_best_epoch_30_final_3rd.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification (1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "traffic_monitor",
   "language": "python",
   "name": "traffic_monitor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
