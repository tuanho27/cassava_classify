{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-30T05:07:28.038434Z",
     "iopub.status.busy": "2020-12-30T05:07:28.037887Z",
     "iopub.status.idle": "2020-12-30T05:07:39.180785Z",
     "shell.execute_reply": "2020-12-30T05:07:39.181308Z"
    },
    "papermill": {
     "duration": 11.168049,
     "end_time": "2020-12-30T05:07:39.181515",
     "exception": false,
     "start_time": "2020-12-30T05:07:28.013466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/cassavav01\n",
      "/kaggle/input/cassavav01/utils\n",
      "/kaggle/input/cassavav01/weights\n",
      "/kaggle/input/cassavav01/pytorch-image-models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/tests\n",
      "/kaggle/input/cassavav01/pytorch-image-models/results\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/ISSUE_TEMPLATE\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/workflows\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs/javascripts\n",
      "/kaggle/input/cassavav01/pytorch-image-models/notebooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/utils\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/scheduler\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/optim\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/loss\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/pruned\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/layers\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/data\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/info\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/hooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects/pack\n",
      "/kaggle/input/cassavav01/pytorch-image-models/convert\n",
      "/kaggle/input/cassava-leaf-disease-classification\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_images\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_images\n",
      "/kaggle/input/cassavav08\n",
      "/kaggle/input/cassavav10\n",
      "/kaggle/input/cassava-packages\n",
      "/kaggle/input/cassavav05\n",
      "/kaggle/input/cassavav07\n",
      "/kaggle/input/cassava-checkpoints\n",
      "/kaggle/input/cassava-checkpoints/eb4_640_fold3.pth\n",
      "/kaggle/input/cassava-checkpoints/cnn_lv2_fold0.pth\n",
      "/kaggle/input/cassava-checkpoints/eb6_512_fold1.pth\n",
      "/kaggle/input/cassava-checkpoints/vitb16_384_fold2.pth\n",
      "/kaggle/input/cassava-checkpoints/eb6_512_fold0.pth\n",
      "/kaggle/input/cassava-checkpoints/eb4_640_fold0.pth\n",
      "/kaggle/input/cassava-checkpoints/eb4_640_fold2.pth\n",
      "/kaggle/input/cassava-checkpoints/sr101_448_fold0.pth\n",
      "/kaggle/input/cassava-checkpoints/cnn_lv2_fold2.pth\n",
      "/kaggle/input/cassava-checkpoints/vitb16_384_fold3.pth\n",
      "/kaggle/input/cassava-checkpoints/cnn_lv2_fold1.pth\n",
      "/kaggle/input/cassava-checkpoints/sr101_448_fold2.pth\n",
      "/kaggle/input/cassava-checkpoints/eb4_640_fold4.pth\n",
      "/kaggle/input/cassava-checkpoints/eb6_512_fold4.pth\n",
      "/kaggle/input/cassava-checkpoints/cnn_lv2_fold3.pth\n",
      "/kaggle/input/cassava-checkpoints/eb6_512_fold2.pth\n",
      "/kaggle/input/cassava-checkpoints/sr101_448_fold3.pth\n",
      "/kaggle/input/cassava-checkpoints/vitb16_384_fold4.pth\n",
      "/kaggle/input/cassava-checkpoints/vitb16_384_fold0.pth\n",
      "/kaggle/input/cassava-checkpoints/eb4_640_fold1.pth\n",
      "/kaggle/input/cassava-checkpoints/sr101_448_fold4.pth\n",
      "/kaggle/input/cassava-checkpoints/eb6_512_fold3.pth\n",
      "/kaggle/input/cassava-checkpoints/vitb16_384_fold1.pth\n",
      "/kaggle/input/cassava-checkpoints/cnn_lv2_fold4.pth\n",
      "/kaggle/input/cassava-checkpoints/sr101_448_fold1.pth\n",
      "/kaggle/input/cassavav06\n",
      "/kaggle/input/cassavav03\n",
      "/kaggle/input/cassavav12\n",
      "/kaggle/input/cassavav09\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "    if \"checkpoints\" in dirname:\n",
    "        for f in filenames:\n",
    "            print(f\"{dirname}/{f}\")\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:07:39.232795Z",
     "iopub.status.busy": "2020-12-30T05:07:39.221249Z",
     "iopub.status.idle": "2020-12-30T05:08:10.823784Z",
     "shell.execute_reply": "2020-12-30T05:08:10.822500Z"
    },
    "papermill": {
     "duration": 31.62437,
     "end_time": "2020-12-30T05:08:10.823946",
     "exception": false,
     "start_time": "2020-12-30T05:07:39.199576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/cassavav01/pytorch-image-models > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:10.893196Z",
     "iopub.status.busy": "2020-12-30T05:08:10.892339Z",
     "iopub.status.idle": "2020-12-30T05:08:35.326223Z",
     "shell.execute_reply": "2020-12-30T05:08:35.325633Z"
    },
    "papermill": {
     "duration": 24.472747,
     "end_time": "2020-12-30T05:08:35.326333",
     "exception": false,
     "start_time": "2020-12-30T05:08:10.853586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/cassava-packages/pretrainedmodels-0.7.4-py37hc8dfbb8_0.xyz ./pretrainedmodels-0.7.4-py37hc8dfbb8_0.tar.bz2\n",
    "!conda install ./pretrainedmodels-0.7.4-py37hc8dfbb8_0.tar.bz2  > /dev/null\n",
    "!rm -rf ./pretrainedmodels-0.7.4-py37hc8dfbb8_0.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:35.368627Z",
     "iopub.status.busy": "2020-12-30T05:08:35.365787Z",
     "iopub.status.idle": "2020-12-30T05:08:36.013183Z",
     "shell.execute_reply": "2020-12-30T05:08:36.012173Z"
    },
    "papermill": {
     "duration": 0.668882,
     "end_time": "2020-12-30T05:08:36.013293",
     "exception": false,
     "start_time": "2020-12-30T05:08:35.344411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/cassavav01/utils . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:36.058258Z",
     "iopub.status.busy": "2020-12-30T05:08:36.057438Z",
     "iopub.status.idle": "2020-12-30T05:08:40.090549Z",
     "shell.execute_reply": "2020-12-30T05:08:40.089154Z"
    },
    "papermill": {
     "duration": 4.059759,
     "end_time": "2020-12-30T05:08:40.090655",
     "exception": false,
     "start_time": "2020-12-30T05:08:36.030896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "cudnn.benchmark = True\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "import pretrainedmodels\n",
    "from utils import Mixup, RandAugment\n",
    "from PIL import Image\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:40.131560Z",
     "iopub.status.busy": "2020-12-30T05:08:40.130887Z",
     "iopub.status.idle": "2020-12-30T05:08:40.136589Z",
     "shell.execute_reply": "2020-12-30T05:08:40.136141Z"
    },
    "papermill": {
     "duration": 0.028565,
     "end_time": "2020-12-30T05:08:40.136676",
     "exception": false,
     "start_time": "2020-12-30T05:08:40.108111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:40.174908Z",
     "iopub.status.busy": "2020-12-30T05:08:40.174328Z",
     "iopub.status.idle": "2020-12-30T05:08:40.182279Z",
     "shell.execute_reply": "2020-12-30T05:08:40.181761Z"
    },
    "papermill": {
     "duration": 0.0284,
     "end_time": "2020-12-30T05:08:40.182367",
     "exception": false,
     "start_time": "2020-12-30T05:08:40.153967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_tfrecords',\n",
       " 'sample_submission.csv',\n",
       " 'test_tfrecords',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_images',\n",
       " 'train.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.join(os.environ[\"HOME\"], \"/kaggle/input/cassava-leaf-disease-classification\")\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:40.224565Z",
     "iopub.status.busy": "2020-12-30T05:08:40.224049Z",
     "iopub.status.idle": "2020-12-30T05:08:40.642335Z",
     "shell.execute_reply": "2020-12-30T05:08:40.643390Z"
    },
    "papermill": {
     "duration": 0.443882,
     "end_time": "2020-12-30T05:08:40.643564",
     "exception": false,
     "start_time": "2020-12-30T05:08:40.199682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "test = pd.read_csv(f'{root}/sample_submission.csv')\n",
    "label_map = pd.read_json(f'{root}/label_num_to_disease_map.json', \n",
    "                         orient='index')\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:40.741994Z",
     "iopub.status.busy": "2020-12-30T05:08:40.741210Z",
     "iopub.status.idle": "2020-12-30T05:08:41.155994Z",
     "shell.execute_reply": "2020-12-30T05:08:41.154857Z"
    },
    "papermill": {
     "duration": 0.467146,
     "end_time": "2020-12-30T05:08:41.156118",
     "exception": false,
     "start_time": "2020-12-30T05:08:40.688972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeResnext(nn.Module):\n",
    "    def __init__(self, backbone, pretrained, num_classes, in_features):\n",
    "        super(SeResnext, self).__init__()\n",
    "        if pretrained:\n",
    "            self.base = pretrainedmodels.__dict__[backbone](pretrained='imagenet')\n",
    "        else:\n",
    "            self.base = pretrainedmodels.__dict__[backbone](pretrained=None)\n",
    "        self.base.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.base.last_linear = nn.Identity()\n",
    "        self.fc1 = nn.Linear(in_features, 2048, bias=True)\n",
    "        self.fc2 = nn.Linear(2048, 1024, bias=True)\n",
    "        self.last_linear = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.212291Z",
     "iopub.status.busy": "2020-12-30T05:08:41.211576Z",
     "iopub.status.idle": "2020-12-30T05:08:41.215158Z",
     "shell.execute_reply": "2020-12-30T05:08:41.214725Z"
    },
    "papermill": {
     "duration": 0.032477,
     "end_time": "2020-12-30T05:08:41.215250",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.182773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ENet(nn.Module):\n",
    "    def __init__(self, backbone, pretrained, num_classes, in_features):\n",
    "        super(ENet, self).__init__()\n",
    "        self.base = timm.create_model(backbone, pretrained=pretrained, num_classes=0)\n",
    "        self.fc1 = nn.Linear(in_features, 2048, bias=True)\n",
    "        self.fc2 = nn.Linear(2048, 1024, bias=True)\n",
    "        self.last_linear = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.last_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.267838Z",
     "iopub.status.busy": "2020-12-30T05:08:41.265979Z",
     "iopub.status.idle": "2020-12-30T05:08:41.268577Z",
     "shell.execute_reply": "2020-12-30T05:08:41.269028Z"
    },
    "papermill": {
     "duration": 0.034555,
     "end_time": "2020-12-30T05:08:41.269135",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.234580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_name = [\"resnest26d\", \"resnest50d\" ,\"tf_efficientnet_b3_ns\", \"tf_efficientnet_b4_ns\", \"vit_base_patch16_384\"]\n",
    "\n",
    "\n",
    "WEIGHTS = [\n",
    "\n",
    "    \"../input/cassavav05/resnest26d_fold1_best_epoch_7_final_2nd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold2_best_epoch_4_final_2nd.pth\",\n",
    "#     #\n",
    "    \"../input/cassavav03/tf_efficientnet_b3_ns_fold1_best_epoch_1_final_512.pth\",\n",
    "    #\n",
    "#     \"../input/cassavav06/resnest50d_fold0_best_epoch_13_final_2nd.pth\",\n",
    "    \"../input/cassavav07/resnest50d_fold0_best_epoch_10_final_3rd.pth\",\n",
    "#     \"../input/cassavav08/resnest50d_fold0_best_epoch_16_final_4th.pth\",\n",
    "#     \"../input/cassavav06/resnest50d_fold1_best_epoch_17_final_2nd.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold1_best_epoch_8_final_5th_pseudo.pth\",\n",
    "    \"../input/cassavav06/resnest50d_fold2_best_epoch_22_final_2nd.pth\",\n",
    "#     \"../input/cassavav06/resnest50d_fold3_best_epoch_2_final_2nd.pth\",\n",
    "    \"../input/cassavav07/resnest50d_fold3_best_epoch_1_final_3rd.pth\",\n",
    "#     \"../input/cassavav08/resnest50d_fold3_best_epoch_2_final_4th.pth\",\n",
    "#     \"../input/cassavav06/resnest50d_fold4_best_epoch_10_final_2nd.pth\",\n",
    "    \"../input/cassavav06/resnest50d_fold4_best_epoch_15_final_3rd.pth\",\n",
    "    \"../input/cassavav08/resnest50d_fold4_best_epoch_10_final-4th.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold4_best_epoch_1_final_5th_pseudo.pth\",\n",
    "    #\n",
    "#      \"../input/cassavav10/tf_efficientnet_b4_ns_fold0_best_epoch_8_final_2nd.pth\",\n",
    "#      \"../input/cassavav10/tf_efficientnet_b4_ns_fold1_best_epoch_6_final_2nd.pth\",\n",
    "#      \"../input/cassavav10/tf_efficientnet_b4_ns_fold2_best_epoch_16_final_2nd.pth\",\n",
    "#      \"../input/cassavav10/tf_efficientnet_b4_ns_fold3_best_epoch_18_final_2nd.pth\",\n",
    "#      \"../input/cassavav10/tf_efficientnet_b4_ns_fold4_best_epoch_19_final_2nd.pth\"\n",
    "    \n",
    "    # Dung ckpt\n",
    "#     \"/kaggle/input/cassava-checkpoints/cnn_lv2_fold0.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/cnn_lv2_fold1.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/cnn_lv2_fold2.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/cnn_lv2_fold3.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/cnn_lv2_fold4.pth\",\n",
    "    \n",
    "#     \"/kaggle/input/cassava-checkpoints/eb4_640_fold0.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb4_640_fold1.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb4_640_fold2.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb4_640_fold3.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb4_640_fold4.pth\",\n",
    "\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb6_512_fold0.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb6_512_fold1.pth\",\n",
    "# #     \"/kaggle/input/cassava-checkpoints/eb6_512_fold2.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb6_512_fold3.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/eb6_512_fold4.pth\",\n",
    "    \n",
    "#     \"/kaggle/input/cassava-checkpoints/vitb16_384_fold1.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/vitb16_384_fold0.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/vitb16_384_fold2.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/vitb16_384_fold4.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/vitb16_384_fold3.pth\",\n",
    "\n",
    "#     \"/kaggle/input/cassava-checkpoints/sr101_448_fold0.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/sr101_448_fold1.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/sr101_448_fold2.pth\",\n",
    "#     \"/kaggle/input/cassava-checkpoints/sr101_448_fold3.pth\",\n",
    "    \n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_25_final_3rd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_14_final_2nd_loss.pth\",\n",
    "#     \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_24_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold2_best_epoch_7_final_3rd.pth\",\n",
    "#     \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold2_best_epoch_20_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold1_best_epoch_30_final_3rd.pth\",\n",
    "#     \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold1_best_epoch_20_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold3_best_epoch_16_final_3rd.pth\",\n",
    "#     \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold3_best_epoch_27_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_20_final_3rd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_23_final_2nd.pth\",\n",
    "    \n",
    "]\n",
    "model_index = 3\n",
    "ckpt_index = 0\n",
    "\n",
    "ensemble_models_name = list(2*[\"resnest26d\"] + [\"tf_efficientnet_b3_ns\"] + 7*[\"resnest50d\"] + 7*[\"tf_efficientnet_b4_ns\"])\n",
    "# ensemble_models_name = list(6*[\"resnest50d\"] + 5*[\"tf_efficientnet_b4_ns\"])\n",
    "ensemble_ckpt_index = [i for i in range(len(ensemble_models_name))]\n",
    "\n",
    "params = {\n",
    "    \"visualize\": False,\n",
    "    \"debug\":False,\n",
    "    \"fold\": [0,1,2,3,4],\n",
    "    \"load_pretrained\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"num_classes\": 5,\n",
    "    \"model\": models_name[model_index],\n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 2,\n",
    "    \"drop_block\": 0.2,\n",
    "    \"drop_rate\": 0.2,\n",
    "    \"tta\": True,\n",
    "    \"kfold_pred\":True,\n",
    "    \"error_fix\":False,\n",
    "    \"ensemble\":True,\n",
    "    \"stacking\":False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.319663Z",
     "iopub.status.busy": "2020-12-30T05:08:41.319142Z",
     "iopub.status.idle": "2020-12-30T05:08:41.322976Z",
     "shell.execute_reply": "2020-12-30T05:08:41.322534Z"
    },
    "papermill": {
     "duration": 0.034675,
     "end_time": "2020-12-30T05:08:41.323067",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.288392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, valid_test=False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        self.valid_test = valid_test\n",
    "        if self.valid_test:\n",
    "            self.labels = df['label'].values  \n",
    "        else:\n",
    "            assert ValueError(\"Test data does not have annotation, plz check!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{root}/test_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isinstance(self.transform, list):\n",
    "            outputs = {'images':[],\n",
    "                       'labels':[]}\n",
    "             #image0 = transforms.ToPILImage()(image)\n",
    "             #image0 = self.transform[0](image0)\n",
    "\n",
    "            for trans in self.transform:\n",
    "                augmented = trans(image=image)\n",
    "                image_aug = augmented['image']\n",
    "                outputs[\"images\"].append(image_aug)\n",
    "                del image_aug\n",
    "                \n",
    "            if self.valid_test:\n",
    "                label = torch.tensor(self.labels[idx]).long()\n",
    "                outputs['labels'] = len(self.transform)*[label]\n",
    "            else:\n",
    "                outputs['labels'] = len(self.transform)*[-1]\n",
    "                \n",
    "            return outputs\n",
    "        else:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image'] \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.368008Z",
     "iopub.status.busy": "2020-12-30T05:08:41.367371Z",
     "iopub.status.idle": "2020-12-30T05:08:41.371241Z",
     "shell.execute_reply": "2020-12-30T05:08:41.370813Z"
    },
    "papermill": {
     "duration": 0.028435,
     "end_time": "2020-12-30T05:08:41.371324",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.342889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.417579Z",
     "iopub.status.busy": "2020-12-30T05:08:41.416601Z",
     "iopub.status.idle": "2020-12-30T05:08:41.419719Z",
     "shell.execute_reply": "2020-12-30T05:08:41.420282Z"
    },
    "papermill": {
     "duration": 0.030058,
     "end_time": "2020-12-30T05:08:41.420444",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.390386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_Dung_model(backbone, pretrained_ckpt, num_classes):\n",
    "    if backbone == 'eb6':\n",
    "        model = ENet('tf_efficientnet_b6_ns', False, num_classes, in_features=2304)\n",
    "    elif backbone == 'sr101':\n",
    "        model = SeResnext('se_resnext101_32x4d', False, num_classes, in_features=2048)\n",
    "    else:\n",
    "        raise ValueError('!!! MODELNAME !!!')\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(WEIGHTS[pretrained_ckpt]))\n",
    "    print(f\"Load pretrained model: {backbone},  {WEIGHTS[pretrained_ckpt]}\")\n",
    "    \n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.476580Z",
     "iopub.status.busy": "2020-12-30T05:08:41.474671Z",
     "iopub.status.idle": "2020-12-30T05:08:41.477174Z",
     "shell.execute_reply": "2020-12-30T05:08:41.477587Z"
    },
    "papermill": {
     "duration": 0.035051,
     "end_time": "2020-12-30T05:08:41.477746",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.442695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def declare_model(name, index=None):\n",
    "    if \"efficientnet_b4\" in name :\n",
    "        model = timm.create_model(\n",
    "                params[\"model\"],\n",
    "                pretrained=False,\n",
    "                num_classes=params[\"num_classes\"], \n",
    "                drop_rate=params[\"drop_rate\"], \n",
    "                drop_path_rate=0.2)\n",
    "    elif \"eb6\" in name or \"sr101\" in name:\n",
    "        model = create_Dung_model(name, index, params[\"num_classes\"])\n",
    "        return model\n",
    "        \n",
    "    else:\n",
    "        model = timm.create_model(name,\n",
    "                pretrained=False,\n",
    "                num_classes=params[\"num_classes\"],\n",
    "                drop_rate=params[\"drop_rate\"])\n",
    "    model = model.to(params[\"device\"])\n",
    "    model = torch.nn.DataParallel(model) \n",
    "        \n",
    "    if params[\"load_pretrained\"]:\n",
    "        if index == None: \n",
    "            return model\n",
    "        state_dict = torch.load(WEIGHTS[index])\n",
    "        print(f\"Load pretrained model: {name} \",state_dict[\"preds\"])\n",
    "        print(WEIGHTS[index])\n",
    "        model.load_state_dict(state_dict[\"model\"])\n",
    "        best_acc = state_dict[\"preds\"]   \n",
    "    return model\n",
    "if not params[\"kfold_pred\"] and not params[\"ensemble\"]:\n",
    "    model = declare_model(params[\"model\"], ckpt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.532882Z",
     "iopub.status.busy": "2020-12-30T05:08:41.532295Z",
     "iopub.status.idle": "2020-12-30T05:08:41.549595Z",
     "shell.execute_reply": "2020-12-30T05:08:41.550188Z"
    },
    "papermill": {
     "duration": 0.050763,
     "end_time": "2020-12-30T05:08:41.550338",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.499575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_tta0 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_tta1 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.HorizontalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "transform_tta2 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),        \n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.VerticalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "transform_tta3 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.RandomRotate90(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),     \n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "##### Test TTA with Five Crops\n",
    "transform_crop_tta0 = T.Compose([\n",
    "                T.FiveCrop(params[\"image_size\"]),\n",
    "                T.Lambda(lambda crops: ([T.ToTensor()(crop) for crop in crops])),\n",
    "                T.Lambda(lambda norms: torch.stack([T.Normalize(mean=[0.5], std=[0.5])(norm) for norm in norms]))\n",
    "        ]\n",
    ")\n",
    "test_transform_tta = [transform_tta0, transform_tta1, transform_tta2, transform_tta3]\n",
    "\n",
    "#debug\n",
    "if params['debug']:\n",
    "    print(\"In debug mode\")\n",
    "    test = pd.concat([test,test, test])\n",
    "\n",
    "if params[\"tta\"]:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta)\n",
    "else:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta[0])\n",
    "    \n",
    "test_pred_loader = DataLoader(\n",
    "    test_pred_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params['num_workers'], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.599451Z",
     "iopub.status.busy": "2020-12-30T05:08:41.598571Z",
     "iopub.status.idle": "2020-12-30T05:08:41.603253Z",
     "shell.execute_reply": "2020-12-30T05:08:41.602841Z"
    },
    "papermill": {
     "duration": 0.032325,
     "end_time": "2020-12-30T05:08:41.603352",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.571027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          image_id  label\n",
       "0  2216849948.jpg      4>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.657777Z",
     "iopub.status.busy": "2020-12-30T05:08:41.657215Z",
     "iopub.status.idle": "2020-12-30T05:08:41.661508Z",
     "shell.execute_reply": "2020-12-30T05:08:41.661062Z"
    },
    "papermill": {
     "duration": 0.037259,
     "end_time": "2020-12-30T05:08:41.661594",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.624335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_tta(data, pred):     \n",
    "    unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    if params[\"tta\"]:\n",
    "        figure, ax = plt.subplots(nrows=1, ncols=num_tta, figsize=(12, 6))\n",
    "        for i, image in enumerate(data[\"images\"]):\n",
    "            image = (unorm(image[0]).cpu().numpy()*255).astype(int)\n",
    "            ax.ravel()[i].imshow(image.transpose(2,1,0))\n",
    "            ax.ravel()[i].set_title(str(pred), color='GREEN')\n",
    "            ax.ravel()[i].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    else:\n",
    "        image = (unorm(data).cpu().numpy()*255).astype(int)\n",
    "        imgplot = plt.imshow(image[0].transpose(2,1,0))\n",
    "        imgplot = plt.title(str(pred), color='GREEN')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.708473Z",
     "iopub.status.busy": "2020-12-30T05:08:41.707937Z",
     "iopub.status.idle": "2020-12-30T05:08:41.711451Z",
     "shell.execute_reply": "2020-12-30T05:08:41.711915Z"
    },
    "papermill": {
     "duration": 0.02802,
     "end_time": "2020-12-30T05:08:41.712032",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.684012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gmean(input_x, dim):\n",
    "    log_x = torch.log(input_x)\n",
    "    return torch.exp(torch.mean(log_x, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.770069Z",
     "iopub.status.busy": "2020-12-30T05:08:41.768298Z",
     "iopub.status.idle": "2020-12-30T05:08:41.770815Z",
     "shell.execute_reply": "2020-12-30T05:08:41.771256Z"
    },
    "papermill": {
     "duration": 0.038941,
     "end_time": "2020-12-30T05:08:41.771371",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.732430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tta = len(test_transform_tta)\n",
    "def tta_predict(loader, params, valid_test=False):\n",
    "    outputs = []\n",
    "    preds = []\n",
    "    models = []\n",
    "    for ckpt_idx in params[\"fold\"]:\n",
    "        model = declare_model(params[\"model\"], ckpt_idx)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    #    \n",
    "    stream = tqdm(loader)    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            if params[\"visualize\"]:\n",
    "                visualize_tta(data, pred)\n",
    "            tta_output = []   \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                kfout = [torch.softmax(model(image), dim=1) for model in models]\n",
    "                tta_output.extend(torch.stack(kfout, dim=0))\n",
    "            tta_output = torch.stack(tta_output, dim=0).mean(dim=0)\n",
    "            \n",
    "            pred = torch.argmax(tta_output, dim=1).cpu().numpy()    \n",
    "            if params[\"error_fix\"]:\n",
    "                topk_output, topk_ids = torch.topk(output, params[\"num_classes\"])\n",
    "                for i in range(len(pred)):\n",
    "                    ## adjust the output prediction\n",
    "                    max_1st = topk_ids[i][0]\n",
    "                    max_2nd = topk_ids[i][1]\n",
    "                    if  max_1st == 0 and max_2nd == 4 and output[i][max_2nd] > 0.2:\n",
    "                        pred[i] = max_2nd\n",
    "                    if max_1st == 3 and max_2nd == 2 and output[i][max_2nd] > 0.2:\n",
    "                        pred[i] = max_2nd\n",
    "\n",
    "            preds.extend(pred)\n",
    "            ## For visualize the TTA \n",
    "            if params[\"visualize\"]:\n",
    "                visualize_tta(data, pred)\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.825676Z",
     "iopub.status.busy": "2020-12-30T05:08:41.824812Z",
     "iopub.status.idle": "2020-12-30T05:08:41.828125Z",
     "shell.execute_reply": "2020-12-30T05:08:41.827483Z"
    },
    "papermill": {
     "duration": 0.036795,
     "end_time": "2020-12-30T05:08:41.828237",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.791442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble CV w/ fold predict on validation set\n",
    "def tta_pred_ensemble_model(loader, params, valid_test=False):\n",
    "    stream = tqdm(loader)\n",
    "    models = []\n",
    "    preds = []\n",
    "    print(f\"Ensemble below models: {ensemble_models_name}\")\n",
    "    for name, ckpt in zip(ensemble_models_name, ensemble_ckpt_index):\n",
    "        print(ckpt)\n",
    "        m = declare_model(name, ckpt)  \n",
    "        models.append(m.eval())\n",
    "        del m\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            tta_output = []   \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                kfout = []\n",
    "                for model,name in zip(models, ensemble_models_name):\n",
    "                    if \"eb6\" in name or \"sr_101\" in name:                    \n",
    "                        with torch.cuda.amp.autocast(), torch.no_grad():\n",
    "                            image = image.cuda()\n",
    "                            kfout.append(torch.softmax(model(image), dim=1))\n",
    "                    else:\n",
    "                        kfout.append(torch.softmax(model(image), dim=1))\n",
    "                        \n",
    "                tta_output.extend(torch.stack(kfout, dim=0))\n",
    "            tta_output = torch.stack(tta_output, dim=0).mean(dim=0)\n",
    "            \n",
    "#             if params[\"stacking\"]:\n",
    "#                 tta_output = F.softmax(tta_output, 1).data.cpu().numpy()\n",
    "#                 preds.append(tta_output)\n",
    "\n",
    "            pred = torch.argmax(tta_output, dim=1).cpu().numpy() \n",
    "            preds.extend(pred)\n",
    "\n",
    "#     if params[\"stacking\"]: \n",
    "#         preds = np.vstack(preds).astype(np.float64)\n",
    "#         return preds\n",
    "    \n",
    "    ## For visualize the TTA \n",
    "        if params[\"visualize\"]:\n",
    "            visualize_tta(data, pred)\n",
    "    return preds       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.874176Z",
     "iopub.status.busy": "2020-12-30T05:08:41.872443Z",
     "iopub.status.idle": "2020-12-30T05:08:41.874793Z",
     "shell.execute_reply": "2020-12-30T05:08:41.875220Z"
    },
    "papermill": {
     "duration": 0.026761,
     "end_time": "2020-12-30T05:08:41.875325",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.848564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class CNNLV2Model(nn.Module):\n",
    "#     def __init__(self, num_classes, num_channels):\n",
    "#         super(CNNLV2Model, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(num_channels, 256, kernel_size=(1,3), stride=1, padding=0),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 512, kernel_size=(5,1), stride=1, padding=0),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#         )\n",
    "#         self.fc1 = nn.Linear(512, 1024, bias=True)\n",
    "#         self.fc2 = nn.Linear(1024, 1024, bias=True)\n",
    "#         self.last_linear = nn.Linear(1024, num_classes, bias=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x).view(-1, 512)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = self.last_linear(x)\n",
    "#         return x\n",
    "    \n",
    "# def load_cnn_lv2_checkpoint(checkpoint_dir, num_models=8, fold=0):\n",
    "#     model = CNNLV2Model(num_classes=5, num_channels=num_models)\n",
    "#     model.cuda()\n",
    "#     CHECKPOINT = '{}/cnn_lv2_fold{}.pth'.format(checkpoint_dir, fold)\n",
    "#     model.load_state_dict(torch.load(CHECKPOINT))\n",
    "#     model.eval()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:08:41.958474Z",
     "iopub.status.busy": "2020-12-30T05:08:41.955799Z",
     "iopub.status.idle": "2020-12-30T05:09:28.564065Z",
     "shell.execute_reply": "2020-12-30T05:09:28.564505Z"
    },
    "papermill": {
     "duration": 46.633202,
     "end_time": "2020-12-30T05:09:28.564641",
     "exception": false,
     "start_time": "2020-12-30T05:08:41.931439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble below models: ['resnest26d', 'resnest26d', 'tf_efficientnet_b3_ns', 'resnest50d', 'resnest50d', 'resnest50d', 'resnest50d', 'resnest50d', 'resnest50d', 'resnest50d', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns', 'tf_efficientnet_b4_ns']\n",
      "0\n",
      "Load pretrained model: resnest26d  0.8997\n",
      "../input/cassavav05/resnest26d_fold1_best_epoch_7_final_2nd.pth\n",
      "1\n",
      "Load pretrained model: resnest26d  0.8952\n",
      "../input/cassavav05/resnest26d_fold2_best_epoch_4_final_2nd.pth\n",
      "2\n",
      "Load pretrained model: tf_efficientnet_b3_ns  0.897\n",
      "../input/cassavav03/tf_efficientnet_b3_ns_fold1_best_epoch_1_final_512.pth\n",
      "3\n",
      "Load pretrained model: resnest50d  0.8864\n",
      "../input/cassavav07/resnest50d_fold0_best_epoch_10_final_3rd.pth\n",
      "4\n",
      "Load pretrained model: resnest50d  0.9005\n",
      "../input/cassavav09/resnest50d_fold1_best_epoch_8_final_5th_pseudo.pth\n",
      "5\n",
      "Load pretrained model: resnest50d  0.8953\n",
      "../input/cassavav06/resnest50d_fold2_best_epoch_22_final_2nd.pth\n",
      "6\n",
      "Load pretrained model: resnest50d  0.8906\n",
      "../input/cassavav07/resnest50d_fold3_best_epoch_1_final_3rd.pth\n",
      "7\n",
      "Load pretrained model: resnest50d  0.8916\n",
      "../input/cassavav06/resnest50d_fold4_best_epoch_15_final_3rd.pth\n",
      "8\n",
      "Load pretrained model: resnest50d  0.8939\n",
      "../input/cassavav08/resnest50d_fold4_best_epoch_10_final-4th.pth\n",
      "9\n",
      "Load pretrained model: resnest50d  0.892\n",
      "../input/cassavav09/resnest50d_fold4_best_epoch_1_final_5th_pseudo.pth\n",
      "10\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.893\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_25_final_3rd.pth\n",
      "11\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.8879\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_14_final_2nd_loss.pth\n",
      "12\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.889\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold2_best_epoch_7_final_3rd.pth\n",
      "13\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.896\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold1_best_epoch_30_final_3rd.pth\n",
      "14\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.8888\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold3_best_epoch_16_final_3rd.pth\n",
      "15\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.889\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_20_final_3rd.pth\n",
      "16\n",
      "Load pretrained model: tf_efficientnet_b4_ns  0.8887\n",
      "/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_23_final_2nd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:46<00:00, 46.57s/it]\n"
     ]
    }
   ],
   "source": [
    "if params[\"ensemble\"]:\n",
    "    final_out = tta_pred_ensemble_model(test_pred_loader, params)     \n",
    "else:\n",
    "    final_out = tta_predict(test_pred_loader, params)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025893,
     "end_time": "2020-12-30T05:09:28.617243",
     "exception": false,
     "start_time": "2020-12-30T05:09:28.591350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ****Test stacking (wait)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-30T05:09:28.674525Z",
     "iopub.status.busy": "2020-12-30T05:09:28.674004Z",
     "iopub.status.idle": "2020-12-30T05:09:28.684994Z",
     "shell.execute_reply": "2020-12-30T05:09:28.684495Z"
    },
    "papermill": {
     "duration": 0.041853,
     "end_time": "2020-12-30T05:09:28.685083",
     "exception": false,
     "start_time": "2020-12-30T05:09:28.643230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = final_out \n",
    "test.to_csv('submission.csv', index=False)\n",
    "test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026049,
     "end_time": "2020-12-30T05:09:28.737451",
     "exception": false,
     "start_time": "2020-12-30T05:09:28.711402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 125.740841,
   "end_time": "2020-12-30T05:09:29.823941",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-30T05:07:24.083100",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
