{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-15T17:12:51.719333Z",
     "iopub.status.busy": "2021-01-15T17:12:51.718684Z",
     "iopub.status.idle": "2021-01-15T17:13:07.634758Z",
     "shell.execute_reply": "2021-01-15T17:13:07.635262Z"
    },
    "papermill": {
     "duration": 15.943243,
     "end_time": "2021-01-15T17:13:07.635464",
     "exception": false,
     "start_time": "2021-01-15T17:12:51.692221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/cassavav01\n",
      "/kaggle/input/cassavav01/utils\n",
      "/kaggle/input/cassavav01/weights\n",
      "/kaggle/input/cassavav01/pytorch-image-models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/tests\n",
      "/kaggle/input/cassavav01/pytorch-image-models/results\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/ISSUE_TEMPLATE\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/workflows\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs/javascripts\n",
      "/kaggle/input/cassavav01/pytorch-image-models/notebooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/utils\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/scheduler\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/optim\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/loss\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/pruned\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/layers\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/data\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/info\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/hooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects/pack\n",
      "/kaggle/input/cassavav01/pytorch-image-models/convert\n",
      "/kaggle/input/cassavav11\n",
      "/kaggle/input/cassavav13\n",
      "/kaggle/input/cnnstackingv01\n",
      "/kaggle/input/cassavav04\n",
      "/kaggle/input/effb43rdfold2\n",
      "/kaggle/input/cassavav16\n",
      "legacy_seresnext26_32x4d_fold0_best_epoch_29_final_4th.pth\n",
      "legacy_seresnext26_32x4d_fold2_best_epoch_26_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold1_best_epoch_21_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold3_best_epoch_4_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold4_best_epoch_17_final_5th.pth\n",
      "/kaggle/input/cnnstackingv02\n",
      "/kaggle/input/cassava-leaf-disease-classification\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_images\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_images\n",
      "/kaggle/input/effb45thfold1\n",
      "/kaggle/input/stackingv04\n",
      "/kaggle/input/cassavav06\n",
      "/kaggle/input/stackingv03\n",
      "/kaggle/input/cassavav15\n",
      "/kaggle/input/cassavav09\n",
      "/kaggle/input/cassavav08\n",
      "/kaggle/input/cassavav02\n",
      "/kaggle/input/cassavav07\n",
      "/kaggle/input/cassavav10\n",
      "/kaggle/input/cassavav03\n",
      "/kaggle/input/cassavav12\n",
      "/kaggle/input/cassavav05\n",
      "/kaggle/input/cassavav14\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "    if \"cassavav16\" in dirname:\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:07.723535Z",
     "iopub.status.busy": "2021-01-15T17:13:07.721877Z",
     "iopub.status.idle": "2021-01-15T17:13:41.201834Z",
     "shell.execute_reply": "2021-01-15T17:13:41.200935Z"
    },
    "papermill": {
     "duration": 33.536254,
     "end_time": "2021-01-15T17:13:41.201959",
     "exception": false,
     "start_time": "2021-01-15T17:13:07.665705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/cassavav01/pytorch-image-models > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:41.248690Z",
     "iopub.status.busy": "2021-01-15T17:13:41.244545Z",
     "iopub.status.idle": "2021-01-15T17:13:41.908093Z",
     "shell.execute_reply": "2021-01-15T17:13:41.907060Z"
    },
    "papermill": {
     "duration": 0.686936,
     "end_time": "2021-01-15T17:13:41.908216",
     "exception": false,
     "start_time": "2021-01-15T17:13:41.221280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/cassavav01/utils . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:41.958265Z",
     "iopub.status.busy": "2021-01-15T17:13:41.955299Z",
     "iopub.status.idle": "2021-01-15T17:13:45.109632Z",
     "shell.execute_reply": "2021-01-15T17:13:45.108910Z"
    },
    "papermill": {
     "duration": 3.182418,
     "end_time": "2021-01-15T17:13:45.109740",
     "exception": false,
     "start_time": "2021-01-15T17:13:41.927322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "cudnn.benchmark = True\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from utils import Mixup, RandAugment\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.166797Z",
     "iopub.status.busy": "2021-01-15T17:13:45.164890Z",
     "iopub.status.idle": "2021-01-15T17:13:45.167459Z",
     "shell.execute_reply": "2021-01-15T17:13:45.167909Z"
    },
    "papermill": {
     "duration": 0.038951,
     "end_time": "2021-01-15T17:13:45.168023",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.129072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNStackModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels):\n",
    "        super(CNNStackModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 256, kernel_size=(1,3), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3,1), stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, 1024, bias=True)\n",
    "        self.fc2 = nn.Linear(1024, 1024, bias=True)\n",
    "        self.last_linear = nn.Linear(1024, num_classes, bias=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # self.init_layer()\n",
    "\n",
    "    def init_layer(self):\n",
    "        for layer in self.conv1:\n",
    "            if \"Conv2d\" in str(layer):\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.last_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.212197Z",
     "iopub.status.busy": "2021-01-15T17:13:45.211503Z",
     "iopub.status.idle": "2021-01-15T17:13:45.218183Z",
     "shell.execute_reply": "2021-01-15T17:13:45.217692Z"
    },
    "papermill": {
     "duration": 0.031368,
     "end_time": "2021-01-15T17:13:45.218275",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.186907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.260916Z",
     "iopub.status.busy": "2021-01-15T17:13:45.260268Z",
     "iopub.status.idle": "2021-01-15T17:13:45.269130Z",
     "shell.execute_reply": "2021-01-15T17:13:45.268646Z"
    },
    "papermill": {
     "duration": 0.031565,
     "end_time": "2021-01-15T17:13:45.269244",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.237679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_tfrecords',\n",
       " 'sample_submission.csv',\n",
       " 'test_tfrecords',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_images',\n",
       " 'train.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.join(os.environ[\"HOME\"], \"/kaggle/input/cassava-leaf-disease-classification\")\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.316191Z",
     "iopub.status.busy": "2021-01-15T17:13:45.315597Z",
     "iopub.status.idle": "2021-01-15T17:13:45.706759Z",
     "shell.execute_reply": "2021-01-15T17:13:45.707318Z"
    },
    "papermill": {
     "duration": 0.418773,
     "end_time": "2021-01-15T17:13:45.707487",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.288714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "test = pd.read_csv(f'{root}/sample_submission.csv')\n",
    "label_map = pd.read_json(f'{root}/label_num_to_disease_map.json', \n",
    "                         orient='index')\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.774481Z",
     "iopub.status.busy": "2021-01-15T17:13:45.773621Z",
     "iopub.status.idle": "2021-01-15T17:13:45.776898Z",
     "shell.execute_reply": "2021-01-15T17:13:45.776350Z"
    },
    "papermill": {
     "duration": 0.042036,
     "end_time": "2021-01-15T17:13:45.777032",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.734996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_name = [\"resnest26d\", \"resnest50d\" , \"tf_efficientnet_b4_ns\", \"legacy_seresnext26_32x4d\"]\n",
    "\n",
    "\n",
    "WEIGHTS_26 = [\n",
    "\n",
    "    \"../input/cassavav05/resnest26d_fold0_best_epoch_19_final_3rd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold1_best_epoch_7_final_2nd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold2_best_epoch_4_final_2nd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold3_best_epoch_10_final_3rd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold4_best_epoch_6_final_3rd.pth\"]\n",
    "    #\n",
    "WEIGHTS_50 = [\n",
    "    \"../input/cassavav07/resnest50d_fold0_best_epoch_10_final_3rd.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold1_best_epoch_8_final_5th_pseudo.pth\",\n",
    "    \"../input/cassavav06/resnest50d_fold2_best_epoch_22_final_2nd.pth\",\n",
    "    \"../input/cassavav07/resnest50d_fold3_best_epoch_1_final_3rd.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold4_best_epoch_1_final_5th_pseudo.pth\"]\n",
    "# \n",
    "WEIGHTS_b4 = [\n",
    "\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_25_final_3rd.pth\",\n",
    "    \"../input/effb45thfold1/tf_efficientnet_b4_ns_fold1_best_epoch_26_final_5th.pth\",\n",
    "    \"../input/effb43rdfold2/tf_efficientnet_b4_ns_fold2_best_epoch_29_final_3rd.pth\",\n",
    "    \"/kaggle/input/cassavav13/tf_efficientnet_b4_ns_fold3_best_epoch_14_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_20_final_3rd.pth\"]\n",
    "\n",
    "WEIGHTS_se26 = [\n",
    "         \"../input/cassavav16/legacy_seresnext26_32x4d_fold0_best_epoch_29_final_4th.pth\",\n",
    "         \"../input/cassavav16/legacy_seresnext26_32x4d_fold1_best_epoch_21_final_5th.pth\",\n",
    "         \"../input/cassavav16/legacy_seresnext26_32x4d_fold2_best_epoch_26_final_5th.pth\",\n",
    "         \"../input/cassavav16/legacy_seresnext26_32x4d_fold3_best_epoch_4_final_5th.pth\",\n",
    "         \"../input/cassavav16/legacy_seresnext26_32x4d_fold4_best_epoch_17_final_5th.pth\"]\n",
    "    \n",
    "SKWeights = [\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold0_best_epoch_30.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold1_best_epoch_1.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold2_best_epoch_16.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold3_best_epoch_23.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold4_best_epoch_27.pth\",\n",
    "]\n",
    "\n",
    "SKWeights02 = [\n",
    "        \"../input/cnnstackingv02/cnn-stack_fold0_best_epoch_27.pth\",\n",
    "        \"../input/cnnstackingv02/cnn-stack_fold1_best_epoch_4.pth\",\n",
    "        \"../input/cnnstackingv02/cnn-stack_fold2_best_epoch_9.pth\",\n",
    "        \"../input/cnnstackingv02/cnn-stack_fold3_best_epoch_12.pth\",\n",
    "        \"../input/cnnstackingv02/cnn-stack_fold4_best_epoch_27.pth\",\n",
    "]\n",
    "SKWeights03 = [\n",
    "        \"../input/stackingv03/cnn-stack_fold0_best_epoch_38.pth\",\n",
    "        \"../input/stackingv03/cnn-stack_fold1_best_epoch_4.pth\",\n",
    "        \"../input/stackingv03/cnn-stack_fold2_best_epoch_63.pth\",\n",
    "        \"../input/stackingv03/cnn-stack_fold3_best_epoch_39.pth\",\n",
    "        \"../input/stackingv03/cnn-stack_fold4_best_epoch_48.pth\",\n",
    "]\n",
    "\n",
    "SKWeights04 = [\n",
    "        \"../input/stackingv04/cnn-stack_fold0_best_epoch_25.pth\",\n",
    "        \"../input/stackingv04/cnn-stack_fold1_best_epoch_20.pth\",\n",
    "        \"../input/stackingv04/cnn-stack_fold2_best_epoch_8.pth\",\n",
    "        \"../input/stackingv03/cnn-stack_fold3_best_epoch_39.pth\",\n",
    "        \"../input/stackingv04/cnn-stack_fold4_best_epoch_23.pth\",\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"visualize\": False,\n",
    "    \"debug\":False,\n",
    "    \"fold\": [0,1,2,3,4],\n",
    "    \"load_pretrained\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"num_classes\": 5,\n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 2,\n",
    "    \"drop_block\": 0.2,\n",
    "    \"drop_rate\": 0.2,\n",
    "    \"tta\": True,\n",
    "    \"kfold_pred\":True,\n",
    "    \"error_fix\":False,\n",
    "    \"ensemble\":False,\n",
    "    \"cnn_stack\": True,\n",
    "    \"boosting\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.837076Z",
     "iopub.status.busy": "2021-01-15T17:13:45.836314Z",
     "iopub.status.idle": "2021-01-15T17:13:45.839343Z",
     "shell.execute_reply": "2021-01-15T17:13:45.838850Z"
    },
    "papermill": {
     "duration": 0.038967,
     "end_time": "2021-01-15T17:13:45.839454",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.800487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, valid_test=False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        self.valid_test = valid_test\n",
    "        if self.valid_test:\n",
    "            self.labels = df['label'].values  \n",
    "        else:\n",
    "            assert ValueError(\"Test data does not have annotation, plz check!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{root}/test_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isinstance(self.transform, list):\n",
    "            outputs = {'images':[],\n",
    "                       'labels':[]}\n",
    "             #image0 = transforms.ToPILImage()(image)\n",
    "             #image0 = self.transform[0](image0)\n",
    "\n",
    "            for trans in self.transform:\n",
    "                augmented = trans(image=image)\n",
    "                image_aug = augmented['image']\n",
    "                outputs[\"images\"].append(image_aug)\n",
    "                del image_aug\n",
    "                \n",
    "            if self.valid_test:\n",
    "                label = torch.tensor(self.labels[idx]).long()\n",
    "                outputs['labels'] = len(self.transform)*[label]\n",
    "            else:\n",
    "                outputs['labels'] = len(self.transform)*[-1]\n",
    "                \n",
    "            return outputs\n",
    "        else:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image'] \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.889690Z",
     "iopub.status.busy": "2021-01-15T17:13:45.888935Z",
     "iopub.status.idle": "2021-01-15T17:13:45.891369Z",
     "shell.execute_reply": "2021-01-15T17:13:45.891954Z"
    },
    "papermill": {
     "duration": 0.03081,
     "end_time": "2021-01-15T17:13:45.892082",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.861272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:45.944207Z",
     "iopub.status.busy": "2021-01-15T17:13:45.943414Z",
     "iopub.status.idle": "2021-01-15T17:13:45.946371Z",
     "shell.execute_reply": "2021-01-15T17:13:45.945919Z"
    },
    "papermill": {
     "duration": 0.032763,
     "end_time": "2021-01-15T17:13:45.946486",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.913723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def declare_pred_model(name, weight):\n",
    "    if \"efficientnet\" in name:\n",
    "        model = timm.create_model(\n",
    "                name,\n",
    "                pretrained=False,\n",
    "                num_classes=5, \n",
    "                drop_rate=0.2, \n",
    "                drop_path_rate=0.3)\n",
    "    else:\n",
    "        model = timm.create_model(\n",
    "                name,\n",
    "                pretrained=False,\n",
    "                num_classes=5,\n",
    "                drop_rate=0.2)\n",
    "\n",
    "    model = model.to(params[\"device\"])\n",
    "    model = torch.nn.DataParallel(model) \n",
    "    state_dict = torch.load(weight)\n",
    "    print(f\"Load pretrained model: {name} \",state_dict[\"preds\"])\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    best_acc = state_dict[\"preds\"]   \n",
    "    return model.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.012379Z",
     "iopub.status.busy": "2021-01-15T17:13:46.011374Z",
     "iopub.status.idle": "2021-01-15T17:13:46.014133Z",
     "shell.execute_reply": "2021-01-15T17:13:46.014644Z"
    },
    "papermill": {
     "duration": 0.046412,
     "end_time": "2021-01-15T17:13:46.014794",
     "exception": false,
     "start_time": "2021-01-15T17:13:45.968382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_tta0 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_tta1 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.HorizontalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "transform_tta2 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),        \n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.VerticalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "transform_tta3 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.RandomRotate90(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),     \n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "##### Test TTA with Five Crops\n",
    "test_transform_tta = [transform_tta0, transform_tta1, transform_tta2, transform_tta3]\n",
    "\n",
    "#debug\n",
    "if params['debug']:\n",
    "    print(\"In debug mode\")\n",
    "    test = pd.concat(100*[test])\n",
    "\n",
    "if params[\"tta\"]:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta)\n",
    "else:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta[0])\n",
    "    \n",
    "test_pred_loader = DataLoader(\n",
    "    test_pred_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params['num_workers'], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.073434Z",
     "iopub.status.busy": "2021-01-15T17:13:46.072587Z",
     "iopub.status.idle": "2021-01-15T17:13:46.076705Z",
     "shell.execute_reply": "2021-01-15T17:13:46.076161Z"
    },
    "papermill": {
     "duration": 0.0326,
     "end_time": "2021-01-15T17:13:46.076807",
     "exception": false,
     "start_time": "2021-01-15T17:13:46.044207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          image_id  label\n",
       "0  2216849948.jpg      4>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.134903Z",
     "iopub.status.busy": "2021-01-15T17:13:46.134174Z",
     "iopub.status.idle": "2021-01-15T17:13:46.137602Z",
     "shell.execute_reply": "2021-01-15T17:13:46.138031Z"
    },
    "papermill": {
     "duration": 0.037901,
     "end_time": "2021-01-15T17:13:46.138157",
     "exception": false,
     "start_time": "2021-01-15T17:13:46.100256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_tta(data, pred):     \n",
    "    unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    if params[\"tta\"]:\n",
    "        figure, ax = plt.subplots(nrows=1, ncols=num_tta, figsize=(12, 6))\n",
    "        for i, image in enumerate(data[\"images\"]):\n",
    "            image = (unorm(image[0]).cpu().numpy()*255).astype(int)\n",
    "            ax.ravel()[i].imshow(image.transpose(2,1,0))\n",
    "            ax.ravel()[i].set_title(str(pred), color='GREEN')\n",
    "            ax.ravel()[i].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    else:\n",
    "        image = (unorm(data).cpu().numpy()*255).astype(int)\n",
    "        imgplot = plt.imshow(image[0].transpose(2,1,0))\n",
    "        imgplot = plt.title(str(pred), color='GREEN')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.190546Z",
     "iopub.status.busy": "2021-01-15T17:13:46.188675Z",
     "iopub.status.idle": "2021-01-15T17:13:46.191192Z",
     "shell.execute_reply": "2021-01-15T17:13:46.191703Z"
    },
    "papermill": {
     "duration": 0.030951,
     "end_time": "2021-01-15T17:13:46.191822",
     "exception": false,
     "start_time": "2021-01-15T17:13:46.160871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gmean(input_x, dim):\n",
    "    log_x = torch.log(input_x)\n",
    "    return torch.exp(torch.mean(log_x, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.250693Z",
     "iopub.status.busy": "2021-01-15T17:13:46.249113Z",
     "iopub.status.idle": "2021-01-15T17:13:46.252368Z",
     "shell.execute_reply": "2021-01-15T17:13:46.251906Z"
    },
    "papermill": {
     "duration": 0.037726,
     "end_time": "2021-01-15T17:13:46.252486",
     "exception": false,
     "start_time": "2021-01-15T17:13:46.214760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tta_stack_validate(loader, model, params, fold_idx):\n",
    "    model.eval()\n",
    "    stream = tqdm(loader)\n",
    "    preds = []\n",
    "    probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            tta_output = [] \n",
    "            tta_prob_output = [] \n",
    "            \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                logit = model(image)\n",
    "                tta_output.append(logit)\n",
    "                tta_prob_output.append(torch.softmax(logit, dim=1))\n",
    "            probs.append(torch.stack(tta_prob_output, dim=0).mean(dim=0))\n",
    "            preds.append(torch.stack(tta_output, dim=0).permute(1,0,2))\n",
    "    return torch.cat(preds, dim=0), torch.cat(probs, dim=0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:13:46.314700Z",
     "iopub.status.busy": "2021-01-15T17:13:46.313863Z",
     "iopub.status.idle": "2021-01-15T17:14:38.268506Z",
     "shell.execute_reply": "2021-01-15T17:14:38.269033Z"
    },
    "papermill": {
     "duration": 51.993687,
     "end_time": "2021-01-15T17:14:38.269184",
     "exception": false,
     "start_time": "2021-01-15T17:13:46.275497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.59it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.45it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.52it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.72it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: legacy_seresnext26_32x4d  0.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: legacy_seresnext26_32x4d  0.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: legacy_seresnext26_32x4d  0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.25it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: legacy_seresnext26_32x4d  0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: legacy_seresnext26_32x4d  0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "r26_logit_preds = {\n",
    "        \"logits\":[],\n",
    "        \"probs\":[],\n",
    "    }\n",
    "r50_logit_preds = {\n",
    "        \"logits\":[],\n",
    "        \"probs\":[],\n",
    "    }\n",
    "eb4_logit_preds = {\n",
    "        \"logits\":[],\n",
    "        \"probs\":[],\n",
    "    }\n",
    "se26_logit_preds = {\n",
    "        \"logits\":[],\n",
    "        \"probs\":[],\n",
    "    }\n",
    "for fold_idx in range(5):\n",
    "    r26_model = declare_pred_model(models_name[0], WEIGHTS_26[fold_idx])\n",
    "    r26_outputs = tta_stack_validate(test_pred_loader, r26_model, params, fold_idx)\n",
    "    r26_logit_preds[\"logits\"].append(r26_outputs[0])\n",
    "    r26_logit_preds[\"probs\"].append(r26_outputs[1])\n",
    "    \n",
    "    del r26_outputs\n",
    "del r26_model\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    r50_model = declare_pred_model(models_name[1], WEIGHTS_50[fold_idx])\n",
    "    r50_outputs = tta_stack_validate(test_pred_loader, r50_model, params, fold_idx)\n",
    "    r50_logit_preds[\"logits\"].append(r50_outputs[0])\n",
    "    r50_logit_preds[\"probs\"].append(r50_outputs[1])\n",
    "    del r50_outputs\n",
    "del r50_model\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    eb4_model = declare_pred_model(models_name[2], WEIGHTS_b4[fold_idx])    \n",
    "    eb4_outputs = tta_stack_validate(test_pred_loader, eb4_model, params, fold_idx)\n",
    "    eb4_logit_preds[\"logits\"].append(eb4_outputs[0])\n",
    "    eb4_logit_preds[\"probs\"].append(eb4_outputs[1])\n",
    "    del eb4_outputs\n",
    "del eb4_model\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    se26_model = declare_pred_model(models_name[3], WEIGHTS_se26[fold_idx])\n",
    "    se26_outputs = tta_stack_validate(test_pred_loader, se26_model, params, fold_idx)\n",
    "    se26_logit_preds[\"logits\"].append(se26_outputs[0])\n",
    "    se26_logit_preds[\"probs\"].append(se26_outputs[1])\n",
    "    del se26_outputs\n",
    "del se26_model\n",
    "\n",
    "del test_pred_dataset, test_pred_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:38.397642Z",
     "iopub.status.busy": "2021-01-15T17:14:38.396645Z",
     "iopub.status.idle": "2021-01-15T17:14:38.401353Z",
     "shell.execute_reply": "2021-01-15T17:14:38.400886Z"
    },
    "papermill": {
     "duration": 0.067699,
     "end_time": "2021-01-15T17:14:38.401471",
     "exception": false,
     "start_time": "2021-01-15T17:14:38.333772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r26_logit_preds[\"logits\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:38.526637Z",
     "iopub.status.busy": "2021-01-15T17:14:38.525930Z",
     "iopub.status.idle": "2021-01-15T17:14:38.529645Z",
     "shell.execute_reply": "2021-01-15T17:14:38.530099Z"
    },
    "papermill": {
     "duration": 0.070453,
     "end_time": "2021-01-15T17:14:38.530226",
     "exception": false,
     "start_time": "2021-01-15T17:14:38.459773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackTestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.df[idx]\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image.cpu().numpy().transpose(1,2,0))\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:38.661152Z",
     "iopub.status.busy": "2021-01-15T17:14:38.660145Z",
     "iopub.status.idle": "2021-01-15T17:14:38.668081Z",
     "shell.execute_reply": "2021-01-15T17:14:38.667606Z"
    },
    "papermill": {
     "duration": 0.078682,
     "end_time": "2021-01-15T17:14:38.668178",
     "exception": false,
     "start_time": "2021-01-15T17:14:38.589496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_transform = A.Compose(\n",
    "[\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "stack_data_loaders = []\n",
    "stack_test_data = torch.stack([torch.stack(r26_logit_preds[\"logits\"], dim=0).mean(dim=0)*0.25,\n",
    "                               torch.stack(r50_logit_preds[\"logits\"], dim=0).mean(dim=0)*0.3,\n",
    "                               torch.stack(eb4_logit_preds[\"logits\"], dim=0).mean(dim=0)*0.25,\n",
    "                               torch.stack(se26_logit_preds[\"logits\"],dim=0).mean(dim=0)*0.2\n",
    "                            ])\n",
    "\n",
    "stack_test_data = stack_test_data.permute(1,0,2,3)\n",
    "stack_dataset = StackTestDataset(stack_test_data, transform=stack_transform)\n",
    "stack_data_loader = DataLoader(\n",
    "        stack_dataset, batch_size=128, shuffle=False, pin_memory=True,\n",
    "    )\n",
    "stack_data_loaders.append(stack_data_loader)\n",
    "    \n",
    "stack_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:38.795818Z",
     "iopub.status.busy": "2021-01-15T17:14:38.793929Z",
     "iopub.status.idle": "2021-01-15T17:14:38.796540Z",
     "shell.execute_reply": "2021-01-15T17:14:38.797062Z"
    },
    "papermill": {
     "duration": 0.069585,
     "end_time": "2021-01-15T17:14:38.797180",
     "exception": false,
     "start_time": "2021-01-15T17:14:38.727595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_prob(row, models, label): \n",
    "    return (row[f\"m1_{label}\"] + row[f\"m2_{label}\"] + row[f\"m3_{label}\"] + row[f\"m4_{label}\"])/models\n",
    "\n",
    "def prediction(row, max_value, model_f): \n",
    "    for f in model_f:\n",
    "        if row[f] == max_value:\n",
    "            ind = f.split(\"_\")[-1]\n",
    "            return int(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:38.925357Z",
     "iopub.status.busy": "2021-01-15T17:14:38.919706Z",
     "iopub.status.idle": "2021-01-15T17:14:41.262783Z",
     "shell.execute_reply": "2021-01-15T17:14:41.261757Z"
    },
    "papermill": {
     "duration": 2.405892,
     "end_time": "2021-01-15T17:14:41.262902",
     "exception": false,
     "start_time": "2021-01-15T17:14:38.857010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** Stack models prediction *****************\n",
      "Load stacking model: ../input/stackingv04/cnn-stack_fold0_best_epoch_25.pth, acc: 0.8932\n",
      "Load stacking model: ../input/stackingv04/cnn-stack_fold1_best_epoch_20.pth, acc: 0.9014\n",
      "Load stacking model: ../input/stackingv04/cnn-stack_fold2_best_epoch_8.pth, acc: 0.8952\n",
      "Load stacking model: ../input/stackingv03/cnn-stack_fold3_best_epoch_39.pth, acc: 0.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load stacking model: ../input/stackingv04/cnn-stack_fold4_best_epoch_23.pth, acc: 0.8994\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>m1_0</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>m1_2</th>\n",
       "      <th>m1_3</th>\n",
       "      <th>m1_4</th>\n",
       "      <th>m2_0</th>\n",
       "      <th>m2_1</th>\n",
       "      <th>m2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>m4_median</th>\n",
       "      <th>m4_std</th>\n",
       "      <th>m1_prediction</th>\n",
       "      <th>m2_prediction</th>\n",
       "      <th>m3_prediction</th>\n",
       "      <th>m4_prediction</th>\n",
       "      <th>m1_prediction_prob</th>\n",
       "      <th>m2_prediction_prob</th>\n",
       "      <th>m3_prediction_prob</th>\n",
       "      <th>m4_prediction_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.03845</td>\n",
       "      <td>0.426618</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>0.438964</td>\n",
       "      <td>0.044992</td>\n",
       "      <td>0.084111</td>\n",
       "      <td>0.281687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140053</td>\n",
       "      <td>0.16838</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.424427</td>\n",
       "      <td>0.424427</td>\n",
       "      <td>0.374352</td>\n",
       "      <td>0.424427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label      m1_0     m1_1      m1_2      m1_3      m1_4  \\\n",
       "0  2216849948.jpg      4  0.033824  0.03845  0.426618  0.062144  0.438964   \n",
       "\n",
       "       m2_0      m2_1      m2_2  ...  m4_median   m4_std  m1_prediction  \\\n",
       "0  0.044992  0.084111  0.281687  ...   0.140053  0.16838              4   \n",
       "\n",
       "   m2_prediction  m3_prediction  m4_prediction  m1_prediction_prob  \\\n",
       "0              4              2              4            0.424427   \n",
       "\n",
       "   m2_prediction_prob  m3_prediction_prob  m4_prediction_prob  \n",
       "0            0.424427            0.374352            0.424427  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"***************** Stack models prediction *****************\")\n",
    "if params[\"cnn_stack\"]:\n",
    "    stack_models = []\n",
    "    for ckpt in range(5):\n",
    "        sm = CNNStackModel(params[\"num_classes\"], len(models_name))\n",
    "        sm = sm.to(params[\"device\"])\n",
    "        sm = torch.nn.DataParallel(sm) \n",
    "    #     state_dict = torch.load(SKWeights[ckpt])\n",
    "        state_dict = torch.load(SKWeights04[ckpt])\n",
    "\n",
    "        sm.load_state_dict(state_dict[\"model\"])\n",
    "        acc = state_dict[\"preds\"]\n",
    "    #     print(f\"Load stacking model: {SKWeights[ckpt]}, acc: {acc}\")\n",
    "        print(f\"Load stacking model: {SKWeights04[ckpt]}, acc: {acc}\")\n",
    "\n",
    "        stack_models.append(sm.eval())\n",
    "        del sm\n",
    "\n",
    "    final_out= []\n",
    "    # for i in range(5):\n",
    "    #     out = []\n",
    "    #     for img in tqdm(stack_data_loaders[i]):\n",
    "    #         out.extend(torch.softmax(stack_models[i](img.cuda()), dim = 1))\n",
    "    #     final_out.append(torch.stack(out, dim=0))\n",
    "    # final_out = torch.argmax(torch.stack(final_out, dim=0).mean(dim=0), dim =1).cpu().numpy()\n",
    "\n",
    "    for img in tqdm(stack_data_loader):\n",
    "        kfold_out = [torch.softmax(model(img.cuda()), dim = 1) for model in stack_models]\n",
    "        final_out.extend(torch.stack(kfold_out, dim=0).mean(dim=0))\n",
    "#     final_out\n",
    "    final_prob_cnn = torch.stack(final_out, dim=0).detach().cpu().numpy()\n",
    "    final_out = torch.argmax(torch.stack(final_out, dim=0), dim =1).cpu().numpy()\n",
    "\n",
    "if params[\"boosting\"]:\n",
    "    import lightgbm as lgb\n",
    "#     print(r26_logit_preds[\"probs\"][0].shape)\n",
    "    output_prob_data = np.hstack([np.stack(r26_logit_preds[\"probs\"], axis=0).mean(axis=0),\n",
    "                           np.stack(r50_logit_preds[\"probs\"], axis=0).mean(axis=0),    \n",
    "                           np.stack(eb4_logit_preds[\"probs\"], axis=0).mean(axis=0),    \n",
    "                           np.stack(se26_logit_preds[\"probs\"], axis=0).mean(axis=0), \n",
    "                           ])\n",
    "    print(output_prob_data[:, 0].shape)\n",
    "    stack_data = pd.DataFrame()\n",
    "    stack_data['image_id'] = test['image_id']\n",
    "    stack_data['label'] = test['label']\n",
    "    stack_data['m1_0'] = output_prob_data[:, 0]\n",
    "    stack_data['m1_1'] = output_prob_data[:, 1]\n",
    "    stack_data['m1_2'] = output_prob_data[:, 2]\n",
    "    stack_data['m1_3'] = output_prob_data[:, 3]\n",
    "    stack_data['m1_4'] = output_prob_data[:, 4]\n",
    "\n",
    "    stack_data['m2_0'] = output_prob_data[:, 5]\n",
    "    stack_data['m2_1'] = output_prob_data[:, 6]\n",
    "    stack_data['m2_2'] = output_prob_data[:, 7]\n",
    "    stack_data['m2_3'] = output_prob_data[:, 8]\n",
    "    stack_data['m2_4'] = output_prob_data[:, 9]\n",
    "\n",
    "    stack_data['m3_0'] = output_prob_data[:, 10]\n",
    "    stack_data['m3_1'] = output_prob_data[:, 11]\n",
    "    stack_data['m3_2'] = output_prob_data[:, 12]\n",
    "    stack_data['m3_3'] = output_prob_data[:, 13]\n",
    "    stack_data['m3_4'] = output_prob_data[:, 14]\n",
    "\n",
    "    stack_data['m4_0'] = output_prob_data[:, 15]\n",
    "    stack_data['m4_1'] = output_prob_data[:, 16]\n",
    "    stack_data['m4_2'] = output_prob_data[:, 17]\n",
    "    stack_data['m4_3'] = output_prob_data[:, 18]\n",
    "    stack_data['m4_4'] = output_prob_data[:, 19]\n",
    "\n",
    "    # add feature engineering\n",
    "    m1_f = [f for f in stack_data.columns if \"m1\" in f]\n",
    "    m2_f = [f for f in stack_data.columns if \"m2\" in f]\n",
    "    m3_f = [f for f in stack_data.columns if \"m3\" in f]\n",
    "    m4_f = [f for f in stack_data.columns if \"m4\" in f]\n",
    "\n",
    "    stack_data['m1_max'] = stack_data[m1_f].max(axis=1)\n",
    "    stack_data['m1_min'] = stack_data[m1_f].min(axis=1)\n",
    "    stack_data['m1_median'] = stack_data[m1_f].median(axis=1)\n",
    "    stack_data['m1_std'] = stack_data[m1_f].std(axis=1)\n",
    "    stack_data['m2_max'] = stack_data[m2_f].max(axis=1)\n",
    "    stack_data['m2_min'] = stack_data[m2_f].min(axis=1)\n",
    "    stack_data['m2_median'] = stack_data[m2_f].median(axis=1)\n",
    "    stack_data['m2_std'] = stack_data[m2_f].std(axis=1)\n",
    "    stack_data['m3_max'] = stack_data[m3_f].max(axis=1)\n",
    "    stack_data['m3_min'] = stack_data[m3_f].min(axis=1)\n",
    "    stack_data['m3_median'] = stack_data[m3_f].median(axis=1)\n",
    "    stack_data['m3_std'] = stack_data[m3_f].std(axis=1)\n",
    "    stack_data['m4_max'] = stack_data[m4_f].max(axis=1)\n",
    "    stack_data['m4_min'] = stack_data[m4_f].min(axis=1)\n",
    "    stack_data['m4_median'] = stack_data[m4_f].median(axis=1)\n",
    "    stack_data['m4_std'] = stack_data[m4_f].std(axis=1)\n",
    "    #\n",
    "    stack_data['m1_prediction'] = stack_data.apply(lambda row : prediction(row,row[\"m1_max\"],m1_f), axis = 1) \n",
    "    stack_data['m2_prediction'] = stack_data.apply(lambda row : prediction(row,row[\"m2_max\"],m2_f), axis = 1) \n",
    "    stack_data['m3_prediction'] = stack_data.apply(lambda row : prediction(row,row[\"m3_max\"],m3_f), axis = 1) \n",
    "    stack_data['m4_prediction'] = stack_data.apply(lambda row : prediction(row,row[\"m4_max\"],m4_f), axis = 1) \n",
    "    stack_data['m1_prediction_prob'] = stack_data.apply(lambda row : prediction_prob(row, 4, row[\"m1_prediction\"]), axis = 1) \n",
    "    stack_data['m2_prediction_prob'] = stack_data.apply(lambda row : prediction_prob(row, 4, row[\"m2_prediction\"]), axis = 1) \n",
    "    stack_data['m3_prediction_prob'] = stack_data.apply(lambda row : prediction_prob(row, 4, row[\"m3_prediction\"]), axis = 1) \n",
    "    stack_data['m4_prediction_prob'] = stack_data.apply(lambda row : prediction_prob(row, 4, row[\"m4_prediction\"]), axis = 1) \n",
    "    display(stack_data.head(n=3))\n",
    "    predcols = [col for col in stack_data.columns if col not in ['image_id'] +  ['label']]\n",
    "#     display(predcols)\n",
    "    \n",
    "    # make prediction\n",
    "    preds = np.zeros(shape=(stack_data.shape[0], 5))\n",
    "    for fold in range(5):\n",
    "        Xp = stack_data[predcols].values\n",
    "    \n",
    "        lgbmodel = lgb.Booster(model_file = f'../input/stackingv03/lgb_fold_{fold}.txt')\n",
    "        preds[:,:] = lgbmodel.predict(Xp, num_iteration=lgbmodel.best_iteration)\n",
    "    final_prob_boosting = preds\n",
    "    final_out = preds.argmax(axis = 1).reshape((len(preds),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:41.393303Z",
     "iopub.status.busy": "2021-01-15T17:14:41.392593Z",
     "iopub.status.idle": "2021-01-15T17:14:41.578611Z",
     "shell.execute_reply": "2021-01-15T17:14:41.577766Z"
    },
    "papermill": {
     "duration": 0.252935,
     "end_time": "2021-01-15T17:14:41.578729",
     "exception": false,
     "start_time": "2021-01-15T17:14:41.325794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params[\"cnn_stack\"] and params[\"boosting\"]:\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    final_out = ((final_prob_cnn + final_prob_boosting)/2).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-15T17:14:41.709659Z",
     "iopub.status.busy": "2021-01-15T17:14:41.708982Z",
     "iopub.status.idle": "2021-01-15T17:14:41.720352Z",
     "shell.execute_reply": "2021-01-15T17:14:41.720882Z"
    },
    "papermill": {
     "duration": 0.078288,
     "end_time": "2021-01-15T17:14:41.721004",
     "exception": false,
     "start_time": "2021-01-15T17:14:41.642716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = final_out \n",
    "test.to_csv('submission.csv', index=False)\n",
    "test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.062832,
     "end_time": "2021-01-15T17:14:41.848532",
     "exception": false,
     "start_time": "2021-01-15T17:14:41.785700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 115.750322,
   "end_time": "2021-01-15T17:14:43.113747",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-15T17:12:47.363425",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
