{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-09T05:19:40.616332Z",
     "iopub.status.busy": "2021-01-09T05:19:40.615646Z",
     "iopub.status.idle": "2021-01-09T05:19:57.732262Z",
     "shell.execute_reply": "2021-01-09T05:19:57.732900Z"
    },
    "papermill": {
     "duration": 17.138578,
     "end_time": "2021-01-09T05:19:57.733111",
     "exception": false,
     "start_time": "2021-01-09T05:19:40.594533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/cassavav12\n",
      "/kaggle/input/cassavav07\n",
      "/kaggle/input/cassavav05\n",
      "/kaggle/input/cnnstackingv01\n",
      "/kaggle/input/cassavav01\n",
      "/kaggle/input/cassavav01/utils\n",
      "/kaggle/input/cassavav01/weights\n",
      "/kaggle/input/cassavav01/pytorch-image-models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/tests\n",
      "/kaggle/input/cassavav01/pytorch-image-models/results\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/ISSUE_TEMPLATE\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.github/workflows\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/docs/javascripts\n",
      "/kaggle/input/cassavav01/pytorch-image-models/notebooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/utils\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/scheduler\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/optim\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/loss\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/pruned\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/models/layers\n",
      "/kaggle/input/cassavav01/pytorch-image-models/timm/data\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/info\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/hooks\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/heads\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/logs/refs/remotes/origin\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects\n",
      "/kaggle/input/cassavav01/pytorch-image-models/.git/objects/pack\n",
      "/kaggle/input/cassavav01/pytorch-image-models/convert\n",
      "/kaggle/input/cassavav10\n",
      "/kaggle/input/cassavav11\n",
      "/kaggle/input/cassavav13\n",
      "/kaggle/input/cassavav16\n",
      "legacy_seresnext26_32x4d_fold0_best_epoch_29_final_4th.pth\n",
      "legacy_seresnext26_32x4d_fold2_best_epoch_26_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold1_best_epoch_21_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold3_best_epoch_4_final_5th.pth\n",
      "legacy_seresnext26_32x4d_fold4_best_epoch_17_final_5th.pth\n",
      "/kaggle/input/effb45thfold1\n",
      "/kaggle/input/cassavav04\n",
      "/kaggle/input/cassava-leaf-disease-classification\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_tfrecords\n",
      "/kaggle/input/cassava-leaf-disease-classification/train_images\n",
      "/kaggle/input/cassava-leaf-disease-classification/test_images\n",
      "/kaggle/input/cassavav02\n",
      "/kaggle/input/cassavav14\n",
      "/kaggle/input/cassavav09\n",
      "/kaggle/input/effb43rdfold2\n",
      "/kaggle/input/cassavav03\n",
      "/kaggle/input/cassavav06\n",
      "/kaggle/input/cassavav15\n",
      "/kaggle/input/cassavav08\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "    if \"cassavav16\" in dirname:\n",
    "        for f in filenames:\n",
    "            print(f)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:19:57.778892Z",
     "iopub.status.busy": "2021-01-09T05:19:57.768094Z",
     "iopub.status.idle": "2021-01-09T05:20:30.579186Z",
     "shell.execute_reply": "2021-01-09T05:20:30.578549Z"
    },
    "papermill": {
     "duration": 32.829612,
     "end_time": "2021-01-09T05:20:30.579288",
     "exception": false,
     "start_time": "2021-01-09T05:19:57.749676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/cassavav01/pytorch-image-models > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:30.620295Z",
     "iopub.status.busy": "2021-01-09T05:20:30.615485Z",
     "iopub.status.idle": "2021-01-09T05:20:31.414736Z",
     "shell.execute_reply": "2021-01-09T05:20:31.413609Z"
    },
    "papermill": {
     "duration": 0.820051,
     "end_time": "2021-01-09T05:20:31.414870",
     "exception": false,
     "start_time": "2021-01-09T05:20:30.594819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/cassavav01/utils . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:31.469019Z",
     "iopub.status.busy": "2021-01-09T05:20:31.468064Z",
     "iopub.status.idle": "2021-01-09T05:20:34.579765Z",
     "shell.execute_reply": "2021-01-09T05:20:34.578324Z"
    },
    "papermill": {
     "duration": 3.142379,
     "end_time": "2021-01-09T05:20:34.579885",
     "exception": false,
     "start_time": "2021-01-09T05:20:31.437506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "cudnn.benchmark = True\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
    "from utils import Mixup, RandAugment\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:34.632778Z",
     "iopub.status.busy": "2021-01-09T05:20:34.628502Z",
     "iopub.status.idle": "2021-01-09T05:20:34.646161Z",
     "shell.execute_reply": "2021-01-09T05:20:34.646799Z"
    },
    "papermill": {
     "duration": 0.051164,
     "end_time": "2021-01-09T05:20:34.646960",
     "exception": false,
     "start_time": "2021-01-09T05:20:34.595796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNStackModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels):\n",
    "        super(CNNStackModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, 256, kernel_size=(1,3), stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3,1), stride=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, 1024, bias=True)\n",
    "        self.fc2 = nn.Linear(1024, 1024, bias=True)\n",
    "        self.last_linear = nn.Linear(1024, num_classes, bias=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.last_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:34.688736Z",
     "iopub.status.busy": "2021-01-09T05:20:34.688187Z",
     "iopub.status.idle": "2021-01-09T05:20:34.694235Z",
     "shell.execute_reply": "2021-01-09T05:20:34.693798Z"
    },
    "papermill": {
     "duration": 0.026505,
     "end_time": "2021-01-09T05:20:34.694316",
     "exception": false,
     "start_time": "2021-01-09T05:20:34.667811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:34.728255Z",
     "iopub.status.busy": "2021-01-09T05:20:34.727760Z",
     "iopub.status.idle": "2021-01-09T05:20:34.735306Z",
     "shell.execute_reply": "2021-01-09T05:20:34.734894Z"
    },
    "papermill": {
     "duration": 0.02605,
     "end_time": "2021-01-09T05:20:34.735392",
     "exception": false,
     "start_time": "2021-01-09T05:20:34.709342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_tfrecords',\n",
       " 'sample_submission.csv',\n",
       " 'test_tfrecords',\n",
       " 'label_num_to_disease_map.json',\n",
       " 'train_images',\n",
       " 'train.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = os.path.join(os.environ[\"HOME\"], \"/kaggle/input/cassava-leaf-disease-classification\")\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:34.773886Z",
     "iopub.status.busy": "2021-01-09T05:20:34.773328Z",
     "iopub.status.idle": "2021-01-09T05:20:35.135970Z",
     "shell.execute_reply": "2021-01-09T05:20:35.135514Z"
    },
    "papermill": {
     "duration": 0.38523,
     "end_time": "2021-01-09T05:20:35.136070",
     "exception": false,
     "start_time": "2021-01-09T05:20:34.750840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cassava Bacterial Blight (CBB)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cassava Brown Streak Disease (CBSD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cassava Green Mottle (CGM)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cassava Mosaic Disease (CMD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     0\n",
       "0       Cassava Bacterial Blight (CBB)\n",
       "1  Cassava Brown Streak Disease (CBSD)\n",
       "2           Cassava Green Mottle (CGM)\n",
       "3         Cassava Mosaic Disease (CMD)\n",
       "4                              Healthy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{root}/train.csv')\n",
    "test = pd.read_csv(f'{root}/sample_submission.csv')\n",
    "label_map = pd.read_json(f'{root}/label_num_to_disease_map.json', \n",
    "                         orient='index')\n",
    "display(train.head())\n",
    "display(test.head())\n",
    "display(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.181051Z",
     "iopub.status.busy": "2021-01-09T05:20:35.180345Z",
     "iopub.status.idle": "2021-01-09T05:20:35.183350Z",
     "shell.execute_reply": "2021-01-09T05:20:35.182947Z"
    },
    "papermill": {
     "duration": 0.029499,
     "end_time": "2021-01-09T05:20:35.183440",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.153941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_name = [\"resnest26d\", \"resnest50d\" , \"tf_efficientnet_b4_ns\"]\n",
    "\n",
    "\n",
    "WEIGHTS_26 = [\n",
    "\n",
    "    \"../input/cassavav05/resnest26d_fold0_best_epoch_19_final_3rd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold1_best_epoch_7_final_2nd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold2_best_epoch_4_final_2nd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold3_best_epoch_10_final_3rd.pth\",\n",
    "    \"../input/cassavav05/resnest26d_fold4_best_epoch_6_final_3rd.pth\"]\n",
    "    #\n",
    "WEIGHTS_50 = [\n",
    "    \"../input/cassavav07/resnest50d_fold0_best_epoch_10_final_3rd.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold1_best_epoch_8_final_5th_pseudo.pth\",\n",
    "    \"../input/cassavav06/resnest50d_fold2_best_epoch_22_final_2nd.pth\",\n",
    "    \"../input/cassavav07/resnest50d_fold3_best_epoch_1_final_3rd.pth\",\n",
    "    \"../input/cassavav09/resnest50d_fold4_best_epoch_1_final_5th_pseudo.pth\"]\n",
    "# \n",
    "WEIGHTS_b4 = [\n",
    "\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold0_best_epoch_25_final_3rd.pth\",\n",
    "    \"../input/effb45thfold1/tf_efficientnet_b4_ns_fold1_best_epoch_26_final_5th.pth\",\n",
    "    \"../input/effb43rdfold2/tf_efficientnet_b4_ns_fold2_best_epoch_29_final_3rd.pth\",\n",
    "    \"/kaggle/input/cassavav13/tf_efficientnet_b4_ns_fold3_best_epoch_14_final_2nd.pth\",\n",
    "    \"/kaggle/input/cassavav12/tf_efficientnet_b4_ns_fold4_best_epoch_20_final_3rd.pth\",\n",
    "]\n",
    "\n",
    "SKWeights = [\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold0_best_epoch_30.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold1_best_epoch_1.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold2_best_epoch_16.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold3_best_epoch_23.pth\",\n",
    "        \"../input/cnnstackingv01/cnn-stack_fold4_best_epoch_27.pth\",\n",
    "]\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"visualize\": False,\n",
    "    \"debug\":False,\n",
    "    \"fold\": [0,1,2,3,4],\n",
    "    \"load_pretrained\": True,\n",
    "    \"image_size\": 512,\n",
    "    \"num_classes\": 5,\n",
    "    \"device\": \"cuda\",\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 2,\n",
    "    \"drop_block\": 0.2,\n",
    "    \"drop_rate\": 0.2,\n",
    "    \"tta\": True,\n",
    "    \"kfold_pred\":True,\n",
    "    \"error_fix\":False,\n",
    "    \"ensemble\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.232267Z",
     "iopub.status.busy": "2021-01-09T05:20:35.231352Z",
     "iopub.status.idle": "2021-01-09T05:20:35.233808Z",
     "shell.execute_reply": "2021-01-09T05:20:35.234282Z"
    },
    "papermill": {
     "duration": 0.033418,
     "end_time": "2021-01-09T05:20:35.234398",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.200980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, valid_test=False):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transform = transform\n",
    "        self.valid_test = valid_test\n",
    "        if self.valid_test:\n",
    "            self.labels = df['label'].values  \n",
    "        else:\n",
    "            assert ValueError(\"Test data does not have annotation, plz check!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{root}/test_images/{file_name}'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isinstance(self.transform, list):\n",
    "            outputs = {'images':[],\n",
    "                       'labels':[]}\n",
    "             #image0 = transforms.ToPILImage()(image)\n",
    "             #image0 = self.transform[0](image0)\n",
    "\n",
    "            for trans in self.transform:\n",
    "                augmented = trans(image=image)\n",
    "                image_aug = augmented['image']\n",
    "                outputs[\"images\"].append(image_aug)\n",
    "                del image_aug\n",
    "                \n",
    "            if self.valid_test:\n",
    "                label = torch.tensor(self.labels[idx]).long()\n",
    "                outputs['labels'] = len(self.transform)*[label]\n",
    "            else:\n",
    "                outputs['labels'] = len(self.transform)*[-1]\n",
    "                \n",
    "            return outputs\n",
    "        else:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image'] \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.275152Z",
     "iopub.status.busy": "2021-01-09T05:20:35.274539Z",
     "iopub.status.idle": "2021-01-09T05:20:35.277566Z",
     "shell.execute_reply": "2021-01-09T05:20:35.277068Z"
    },
    "papermill": {
     "duration": 0.026216,
     "end_time": "2021-01-09T05:20:35.277662",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.251446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.320505Z",
     "iopub.status.busy": "2021-01-09T05:20:35.319754Z",
     "iopub.status.idle": "2021-01-09T05:20:35.321968Z",
     "shell.execute_reply": "2021-01-09T05:20:35.322415Z"
    },
    "papermill": {
     "duration": 0.027091,
     "end_time": "2021-01-09T05:20:35.322509",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.295418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def declare_pred_model(name, weight):\n",
    "    if \"efficientnet\" in name:\n",
    "        model = timm.create_model(\n",
    "                name,\n",
    "                pretrained=False,\n",
    "                num_classes=5, \n",
    "                drop_rate=0.2, \n",
    "                drop_path_rate=0.3)\n",
    "    else:\n",
    "        model = timm.create_model(\n",
    "                name,\n",
    "                pretrained=False,\n",
    "                num_classes=5,\n",
    "                drop_rate=0.2)\n",
    "\n",
    "    model = model.to(params[\"device\"])\n",
    "    model = torch.nn.DataParallel(model) \n",
    "    state_dict = torch.load(weight)\n",
    "    print(f\"Load pretrained model: {name} \",state_dict[\"preds\"])\n",
    "    model.load_state_dict(state_dict[\"model\"])\n",
    "    best_acc = state_dict[\"preds\"]   \n",
    "    return model.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.375564Z",
     "iopub.status.busy": "2021-01-09T05:20:35.374912Z",
     "iopub.status.idle": "2021-01-09T05:20:35.377300Z",
     "shell.execute_reply": "2021-01-09T05:20:35.377691Z"
    },
    "papermill": {
     "duration": 0.037584,
     "end_time": "2021-01-09T05:20:35.377791",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.340207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_tta0 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_tta1 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.HorizontalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),   \n",
    "     ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "transform_tta2 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),        \n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.VerticalFlip(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "transform_tta3 = A.Compose(\n",
    "    [\n",
    "     A.CenterCrop(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.Resize(height=params[\"image_size\"], width=params[\"image_size\"], p=1),\n",
    "     A.RandomRotate90(p=1.),\n",
    "     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),     \n",
    "     ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "##### Test TTA with Five Crops\n",
    "test_transform_tta = [transform_tta0, transform_tta1, transform_tta2, transform_tta3]\n",
    "\n",
    "#debug\n",
    "if params['debug']:\n",
    "    print(\"In debug mode\")\n",
    "    test = pd.concat(100*[test])\n",
    "\n",
    "if params[\"tta\"]:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta)\n",
    "else:\n",
    "    test_pred_dataset = TestDataset(test, transform=test_transform_tta[0])\n",
    "    \n",
    "test_pred_loader = DataLoader(\n",
    "    test_pred_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params['num_workers'], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.420589Z",
     "iopub.status.busy": "2021-01-09T05:20:35.419638Z",
     "iopub.status.idle": "2021-01-09T05:20:35.423976Z",
     "shell.execute_reply": "2021-01-09T05:20:35.423536Z"
    },
    "papermill": {
     "duration": 0.027244,
     "end_time": "2021-01-09T05:20:35.424065",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.396821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          image_id  label\n",
       "0  2216849948.jpg      4>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.473048Z",
     "iopub.status.busy": "2021-01-09T05:20:35.472075Z",
     "iopub.status.idle": "2021-01-09T05:20:35.474418Z",
     "shell.execute_reply": "2021-01-09T05:20:35.474884Z"
    },
    "papermill": {
     "duration": 0.032097,
     "end_time": "2021-01-09T05:20:35.474990",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.442893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_tta(data, pred):     \n",
    "    unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    if params[\"tta\"]:\n",
    "        figure, ax = plt.subplots(nrows=1, ncols=num_tta, figsize=(12, 6))\n",
    "        for i, image in enumerate(data[\"images\"]):\n",
    "            image = (unorm(image[0]).cpu().numpy()*255).astype(int)\n",
    "            ax.ravel()[i].imshow(image.transpose(2,1,0))\n",
    "            ax.ravel()[i].set_title(str(pred), color='GREEN')\n",
    "            ax.ravel()[i].set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show() \n",
    "    else:\n",
    "        image = (unorm(data).cpu().numpy()*255).astype(int)\n",
    "        imgplot = plt.imshow(image[0].transpose(2,1,0))\n",
    "        imgplot = plt.title(str(pred), color='GREEN')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.518163Z",
     "iopub.status.busy": "2021-01-09T05:20:35.517393Z",
     "iopub.status.idle": "2021-01-09T05:20:35.520180Z",
     "shell.execute_reply": "2021-01-09T05:20:35.519637Z"
    },
    "papermill": {
     "duration": 0.02644,
     "end_time": "2021-01-09T05:20:35.520265",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.493825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gmean(input_x, dim):\n",
    "    log_x = torch.log(input_x)\n",
    "    return torch.exp(torch.mean(log_x, dim=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.564819Z",
     "iopub.status.busy": "2021-01-09T05:20:35.564130Z",
     "iopub.status.idle": "2021-01-09T05:20:35.567006Z",
     "shell.execute_reply": "2021-01-09T05:20:35.566599Z"
    },
    "papermill": {
     "duration": 0.028083,
     "end_time": "2021-01-09T05:20:35.567088",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.539005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tta_stack_validate(loader, model, params, fold_idx):\n",
    "    model.eval()\n",
    "    stream = tqdm(loader)\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream, start=1):\n",
    "            tta_output = [] \n",
    "            for i, image in enumerate(data[\"images\"]):\n",
    "                logit = model(image)\n",
    "                tta_output.append(logit)\n",
    "            preds.append(torch.stack(tta_output, dim=0).permute(1,0,2))\n",
    "    return torch.cat(preds, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:20:35.615020Z",
     "iopub.status.busy": "2021-01-09T05:20:35.614195Z",
     "iopub.status.idle": "2021-01-09T05:21:18.230600Z",
     "shell.execute_reply": "2021-01-09T05:21:18.229963Z"
    },
    "papermill": {
     "duration": 42.644516,
     "end_time": "2021-01-09T05:21:18.230743",
     "exception": false,
     "start_time": "2021-01-09T05:20:35.586227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.56it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.75it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest26d  0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: tf_efficientnet_b4_ns  0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.03it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model: resnest50d  0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "r26_logit_preds = {\n",
    "        \"logits\":[],\n",
    "    }\n",
    "r50_logit_preds = {\n",
    "        \"logits\":[],\n",
    "    }\n",
    "eb4_logit_preds = {\n",
    "        \"logits\":[],\n",
    "    }\n",
    "for fold_idx in range(5):\n",
    "    r26_model = declare_pred_model(models_name[0], WEIGHTS_26[fold_idx])\n",
    "    r26_outputs = tta_stack_validate(test_pred_loader, r26_model, params, fold_idx)\n",
    "    r26_logit_preds[\"logits\"].append(r26_outputs)\n",
    "    del r26_outputs\n",
    "del r26_model\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    eb4_model = declare_pred_model(models_name[2], WEIGHTS_b4[fold_idx])    \n",
    "    eb4_outputs = tta_stack_validate(test_pred_loader, eb4_model, params, fold_idx)\n",
    "    eb4_logit_preds[\"logits\"].append(eb4_outputs)\n",
    "    del eb4_outputs\n",
    "del eb4_model\n",
    "    \n",
    "for fold_idx in range(5):\n",
    "    r50_model = declare_pred_model(models_name[1], WEIGHTS_50[fold_idx])\n",
    "    r50_outputs = tta_stack_validate(test_pred_loader, r50_model, params, fold_idx)\n",
    "    r50_logit_preds[\"logits\"].append(r50_outputs)\n",
    "    del r50_outputs\n",
    "del r50_model\n",
    "\n",
    "del test_pred_dataset, test_pred_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:18.315297Z",
     "iopub.status.busy": "2021-01-09T05:21:18.314659Z",
     "iopub.status.idle": "2021-01-09T05:21:18.317679Z",
     "shell.execute_reply": "2021-01-09T05:21:18.318065Z"
    },
    "papermill": {
     "duration": 0.047447,
     "end_time": "2021-01-09T05:21:18.318179",
     "exception": false,
     "start_time": "2021-01-09T05:21:18.270732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r26_logit_preds[\"logits\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:18.405437Z",
     "iopub.status.busy": "2021-01-09T05:21:18.403721Z",
     "iopub.status.idle": "2021-01-09T05:21:18.406085Z",
     "shell.execute_reply": "2021-01-09T05:21:18.406478Z"
    },
    "papermill": {
     "duration": 0.049507,
     "end_time": "2021-01-09T05:21:18.406587",
     "exception": false,
     "start_time": "2021-01-09T05:21:18.357080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackTestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.df[idx]\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image.cpu().numpy().transpose(1,2,0))\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:18.493400Z",
     "iopub.status.busy": "2021-01-09T05:21:18.492625Z",
     "iopub.status.idle": "2021-01-09T05:21:18.499223Z",
     "shell.execute_reply": "2021-01-09T05:21:18.498721Z"
    },
    "papermill": {
     "duration": 0.053499,
     "end_time": "2021-01-09T05:21:18.499302",
     "exception": false,
     "start_time": "2021-01-09T05:21:18.445803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_transform = A.Compose(\n",
    "[\n",
    "    ToTensorV2(),\n",
    "])\n",
    "stack_test_data = torch.stack([torch.stack(r26_logit_preds[\"logits\"], dim=0).mean(dim=0),\n",
    "                         torch.stack(r50_logit_preds[\"logits\"], dim=0).mean(dim=0),\n",
    "                         torch.stack(eb4_logit_preds[\"logits\"], dim=0).mean(dim=0)\n",
    "                        ])\n",
    "stack_test_data = stack_test_data.permute(1,0,2,3)\n",
    "stack_dataset = StackTestDataset(stack_test_data, transform=stack_transform)\n",
    "stack_data_loader = DataLoader(\n",
    "        stack_dataset, batch_size=128, shuffle=False, pin_memory=True,\n",
    "    )\n",
    "stack_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:18.586763Z",
     "iopub.status.busy": "2021-01-09T05:21:18.586173Z",
     "iopub.status.idle": "2021-01-09T05:21:20.088086Z",
     "shell.execute_reply": "2021-01-09T05:21:20.088677Z"
    },
    "papermill": {
     "duration": 1.549894,
     "end_time": "2021-01-09T05:21:20.088849",
     "exception": false,
     "start_time": "2021-01-09T05:21:18.538955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** Stack models prediction *****************\n",
      "Load stacking model: ../input/cnnstackingv01/cnn-stack_fold0_best_epoch_30.pth, acc: 0.8914\n",
      "Load stacking model: ../input/cnnstackingv01/cnn-stack_fold1_best_epoch_1.pth, acc: 0.9002\n",
      "Load stacking model: ../input/cnnstackingv01/cnn-stack_fold2_best_epoch_16.pth, acc: 0.8998\n",
      "Load stacking model: ../input/cnnstackingv01/cnn-stack_fold3_best_epoch_23.pth, acc: 0.8902\n",
      "Load stacking model: ../input/cnnstackingv01/cnn-stack_fold4_best_epoch_27.pth, acc: 0.8987\n"
     ]
    }
   ],
   "source": [
    "print(f\"***************** Stack models prediction *****************\")\n",
    "stack_models = []\n",
    "for ckpt in range(5):\n",
    "    sm = CNNStackModel(params[\"num_classes\"], len(models_name))\n",
    "    sm = sm.to(params[\"device\"])\n",
    "    sm = torch.nn.DataParallel(sm) \n",
    "    state_dict = torch.load(SKWeights[ckpt])\n",
    "    sm.load_state_dict(state_dict[\"model\"])\n",
    "    acc = state_dict[\"preds\"]\n",
    "    print(f\"Load stacking model: {SKWeights[ckpt]}, acc: {acc}\")\n",
    "    \n",
    "    stack_models.append(sm.eval())\n",
    "    del sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:20.190279Z",
     "iopub.status.busy": "2021-01-09T05:21:20.188044Z",
     "iopub.status.idle": "2021-01-09T05:21:20.214266Z",
     "shell.execute_reply": "2021-01-09T05:21:20.213657Z"
    },
    "papermill": {
     "duration": 0.07576,
     "end_time": "2021-01-09T05:21:20.214399",
     "exception": false,
     "start_time": "2021-01-09T05:21:20.138639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 49.92it/s]\n"
     ]
    }
   ],
   "source": [
    "final_out = []\n",
    "for img in tqdm(stack_data_loader):\n",
    "    kfold_out = [torch.softmax(model(img.cuda()), dim = 1) for model in stack_models]\n",
    "    final_out.extend(torch.stack(kfold_out, dim=0).mean(dim=0))\n",
    "\n",
    "final_out = torch.argmax(torch.stack(final_out, dim=0), dim =1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-09T05:21:20.306104Z",
     "iopub.status.busy": "2021-01-09T05:21:20.305466Z",
     "iopub.status.idle": "2021-01-09T05:21:20.317521Z",
     "shell.execute_reply": "2021-01-09T05:21:20.317006Z"
    },
    "papermill": {
     "duration": 0.059748,
     "end_time": "2021-01-09T05:21:20.317625",
     "exception": false,
     "start_time": "2021-01-09T05:21:20.257877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'] = final_out \n",
    "test.to_csv('submission.csv', index=False)\n",
    "test.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.042753,
     "end_time": "2021-01-09T05:21:20.403594",
     "exception": false,
     "start_time": "2021-01-09T05:21:20.360841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 104.793155,
   "end_time": "2021-01-09T05:21:21.593987",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-09T05:19:36.800832",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
